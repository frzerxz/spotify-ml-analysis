{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine Öğrenmesi Dönem Ödevi Projesi Raporu (F2025)\n",
    "\n",
    "**Öğrenci Adı Soyadı:** Firuze Eroğlu  \n",
    "**Öğrenci No:** 201613709044  \n",
    "**Teslim Tarihi:** 14.12.2025  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Veri Seti Tanıtımı\n",
    "\n",
    "Bu projede üç farklı makine öğrenmesi problemi için, müzik endüstrisinin en büyük platformu Spotify'dan elde edilen gerçek dünya verileri kullanılmıştır. Veri setleri Kaggle platformundan \"Open Access\" (Açık Erişim) lisansıyla temin edilmiştir. Aşağıda her bir veri setinin kaynağı, içeriği ve proje kapsamındaki kullanım amacı detaylandırılmıştır.\n",
    "\n",
    "### 1.1. Sınıflandırma Veri Seti: Spotify Tracks Dataset\n",
    "*   **Veri Kaynağı Linki:** [Kaggle - Spotify Tracks Dataset](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)\n",
    "*   **Veri Seti Tanımı:** Bu veri seti, Spotify üzerindeki 125 farklı müzik türünden yaklaşık 114.000 şarkıyı kapsamaktadır. Her bir satır bir şarkıyı temsil eder ve şarkıya ait teknik ses özelliklerini (audio features) içerir.\n",
    "*   **Problem ve Tahmin Hedefi:**\n",
    "    *   **Problem:** Müzik endüstrisinde bir şarkının \"Hit\" olup olmayacağını, şarkı henüz piyasaya çıkmadan sadece ses analizine dayanarak öngörmek büyük bir ticari değer taşır.\n",
    "    *   **Hedef:** Şarkının `danceability`, `energy`, `loudness` gibi teknik ses özniteliklerini kullanarak, şarkının **\"Popüler\"** (Popularity > 50) olup olmadığını sınıflandırmaya çalışıyoruz. Bu, **Binary Classification** problemidir.\n",
    "\n",
    "### 1.2. Regresyon Veri Seti: Spotify Global Music Dataset\n",
    "*   **Veri Kaynağı Linki:** [Kaggle - Spotify Global Music Dataset 2009-2025](https://www.kaggle.com/datasets/wardabilal/spotify-global-music-dataset-20092025?select=spotify_data+clean.csv) (Kullanılan dosya: `spotify_data clean.csv`)\n",
    "*   **Veri Seti Tanımı:** 2009-2025 yılları arasındaki küresel müzik trendlerini içeren veri setidir.\n",
    "*   **Hedef:** Şarkının ve sanatçının metadatalarını kullanarak, şarkının Spotify üzerindeki **Popülerlik Puanını (0-100)** tahmin etmek.\n",
    "\n",
    "### 1.3. Kümeleme Veri Seti: Most Streamed Spotify Songs 2024\n",
    "*   **Veri Kaynağı Linki:** [Kaggle - Most Streamed Spotify Songs 2024](https://www.kaggle.com/datasets/nelgiriyewithana/most-streamed-spotify-songs-2024)\n",
    "*   **Veri Seti Tanımı:** 2024 yılının en çok dinlenen şarkılarını ve etkileşim sayılarını içerir.\n",
    "*   **Hedef:** Şarkıları dinlenme ve etkileşimlerine göre **Segmentlere (Kümeler)** ayırmak (Unsupervised Learning).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Uygulanan Yöntemler ve Ön İşleme\n",
    "(Raporun bu kısmı orijinal dokümandaki gibidir: Eksik veriler, ölçekleme, one-hot encoding, undersampling ve outlier temizliği uygulanmıştır.)\n",
    "\n",
    "## 3. Sonuçlar ve Metrikler\n",
    "(Detaylı sonuçlar ve grafik yorumları Notebook çıktılarında yer alacaktır.)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- OTOMATİK VERİ İNDİRME FONKSİYONU ---\n",
    "def load_data_from_github(filename, url):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Dosya yerelde bulunamadı: {filename}\")\n",
    "        print(f\"GitHub'dan indiriliyor... ({url})\")\n",
    "        try:\n",
    "            # Colab/Linux/Windows uyumlu indirme (wget veya curl)\n",
    "            if os.system(f'wget -O \"{filename}\" \"{url}\"') != 0:\n",
    "                # Wget çalışmazsa curl dene\n",
    "                os.system(f'curl -L \"{url}\" -o \"{filename}\"')\n",
    "            print(\"İndirme tamamlandı.\")\n",
    "        except Exception as e:\n",
    "            print(f\"İndirme Hatası: {e}\")\n",
    "    else:\n",
    "        print(f\"Dosya zaten mevcut: {filename}\")\n",
    "    \n",
    "    # Okuma\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "    except:\n",
    "        # Kodlama hatası olursa\n",
    "        df = pd.read_csv(filename, encoding='ISO-8859-1')\n",
    "    return df\n",
    "\n",
    "print(\"Veri indirme ve yükleme altyapısı hazır.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CLASSIFICATION TASK ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg') # Notebook'ta grafik görmek için bunu kapatıyoruz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import time\n",
    "\n",
    "print(\"--- CLASSIFICATION BAŞLIYOR ---\")\n",
    "# GitHub URL'si\n",
    "URL_CLASS = \"https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/dataset.csv\"\n",
    "# Veriyi Yükle (Otomatik Fonksiyon ile)\n",
    "df = load_data_from_github('dataset.csv', URL_CLASS)\n",
    "\n",
    "print(f\"Veri seti boyutu: {df.shape}\")\n",
    "\n",
    "target_col = 'is_popular'\n",
    "df[target_col] = (df['popularity'] > 50).astype(int)\n",
    "\n",
    "cols_to_drop = ['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'track_genre']\n",
    "feature_cols = [c for c in df.columns if c not in cols_to_drop and c != target_col]\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "if 'explicit' in X.columns:\n",
    "    X['explicit'] = X['explicit'].astype(int)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Undersampling\n",
    "try:\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    # Pipeline entegrasyonu olmadığı için önce preprocess etmek gerekir ama \n",
    "    # burada basitlik adına orjinal logic'i koruyoruz\n",
    "    print(\"Under-sampling uygulanıyor...\")\n",
    "    # Not: imblearn ile pipeline kullanımı farklıdır, burada manuel dengelemeyi simüle eden kodun\n",
    "    # çalışması için veri tiplerini korumalıyız.\n",
    "    # Kullanıcının orjinal kodunda bu kısım preprocess öncesi yapılmıştı. Biz de öyle yapalım:\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    X_train = X_train_resampled\n",
    "    y_train = y_train_resampled\n",
    "except ImportError:\n",
    "    print(\"UYARI: imblearn yok.\")\n",
    "\n",
    "# Ön İşleme\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model Eğitimi (Örnek: RandomForest)\n",
    "print(\"Model Eğitiliyor (Random Forest)...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_processed, y_train)\n",
    "y_pred = rf.predict(X_test_processed)\n",
    "\n",
    "print(\"Classification Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. REGRESSION TASK ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(\"\\n--- REGRESSION BAŞLIYOR ---\")\n",
    "URL_REG = \"https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/spotify_data%20clean.csv\"\n",
    "# Veriyi Yükle (Dosya adındaki boşluk sorununu URL encode ile çözdük)\n",
    "df_reg = load_data_from_github('spotify_data clean.csv', URL_REG)\n",
    "\n",
    "print(f\"Veri seti boyutu: {df_reg.shape}\")\n",
    "\n",
    "target_col = 'track_popularity'\n",
    "# Basit özellik seçimi (Orjinal koddaki gibi)\n",
    "cols_to_drop = ['track_id', 'track_name', 'artist_name', 'album_id', 'album_name', 'album_release_date', 'artist_genres', target_col]\n",
    "X = df_reg.drop(columns=[c for c in cols_to_drop if c in df_reg.columns])\n",
    "y = df_reg[target_col]\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Pipeline\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "print(\"Model Eğitiliyor (Random Forest Regressor)...\")\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', rf_reg)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CLUSTERING TASK ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"\\n--- CLUSTERING BAŞLIYOR ---\")\n",
    "# DÜZELTME: Dosya adı alt çizgili olacak\n",
    "filename_clust = 'Most_Streamed_Spotify_Songs_2024.csv'\n",
    "URL_CLUST = \"https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/Most_Streamed_Spotify_Songs_2024.csv\"\n",
    "\n",
    "df_clust = load_data_from_github(filename_clust, URL_CLUST)\n",
    "print(f\"Veri Boyutu: {df_clust.shape}\")\n",
    "\n",
    "# Gereksiz sütunları at\n",
    "drop_cols = ['Track', 'Album Name', 'Artist', 'ISRC', 'All Time Rank', 'Release Date']\n",
    "X = df_clust.drop(columns=[c for c in drop_cols if c in df_clust.columns])\n",
    "\n",
    "# Virgülleri temizle ve sayıya çevir\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == object:\n",
    "        X[col] = pd.to_numeric(X[col].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "X = X.fillna(0)\n",
    "# İlk 5000 satır (Hız için)\n",
    "if len(X) > 5000:\n",
    "    X = X.iloc[:5000]\n",
    "\n",
    "# Ölçekleme\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# KMeans\n",
    "print(\"K-Means çalıştırılıyor (K=3)...\")\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette_score(X_scaled, labels):.4f}\")\n",
    "print(\"Kümeleme tamamlandı.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}