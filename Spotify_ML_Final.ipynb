{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽµ Spotify Data Analysis & Machine Learning Project\n",
    "\n",
    "**Ã–ÄŸrenci:** Firuze EroÄŸlu (201613709044)  \n",
    "**Ders:** Machine Learning (Fall 2025)\n",
    "\n",
    "Bu proje, Spotify verilerini kullanarak uÃ§tan uca Ã¼Ã§ farklÄ± makine Ã¶ÄŸrenmesi problemini ele almaktadÄ±r:\n",
    "1.  **SÄ±nÄ±flandÄ±rma (Classification):** ÅžarkÄ± Ã¶zelliklerine gÃ¶re popÃ¼lerlik tahmini.\n",
    "2.  **Regresyon (Regression):** ÅžarkÄ±larÄ±n popÃ¼lerlik puanÄ±nÄ±n (0-100) tahmini.\n",
    "3.  **KÃ¼meleme (Clustering):** ÅžarkÄ±larÄ±n dinlenme sayÄ±larÄ±na gÃ¶re segmentasyonu.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KÃ¼tÃ¼phanelerin YÃ¼klenmesi ve Ayarlar\n",
    "Gerekli olan `pandas`, `sklearn`, `xgboost` gibi veri bilimi kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Scikit-Learn ModÃ¼lleri\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, _classification_report, r2_score, mean_squared_error)\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# UyarÄ±larÄ± kapat (Temiz Ã§Ä±ktÄ± iÃ§in)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Setlerinin YÃ¼klenmesi (Otomatik)\n",
    "Bu kod bloÄŸu, Ã§alÄ±ÅŸma ortamÄ±nÄ± (Local veya Google Colab) algÄ±lar. EÄŸer veri setleri yerel dizinde yoksa, **GitHub deposundan otomatik olarak indirir.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VERÄ° Ä°NDÄ°RME FONKSÄ°YONU ---\n",
    "def load_data_from_github(filename, url):\n",
    "    # 1. Dosya yerelde var mÄ± kontrol et\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"[BILGI] '{filename}' bulunamadÄ±, GitHub'dan indiriliyor...\")\n",
    "        try:\n",
    "            # Wget komutu ile dosyayÄ± Ã§ek\n",
    "            os.system(f'wget -O \"{filename}\" \"{url}\"')\n",
    "            print(\"[BASARILI] Ä°ndirme tamamlandÄ±.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] Ä°ndirme baÅŸarÄ±sÄ±z: {e}\")\n",
    "    else:\n",
    "        print(f\"[BILGI] '{filename}' zaten mevcut, yÃ¼kleniyor...\")\n",
    "    \n",
    "    # 2. DosyayÄ± Oku (Encoding hatasÄ±na karÅŸÄ± Ã¶nlem alarak)\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "    except:\n",
    "        df = pd.read_csv(filename, encoding='ISO-8859-1')\n",
    "    return df\n",
    "\n",
    "# URL TanÄ±mlarÄ±\n",
    "URL_CLASS = \"https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/dataset.csv\"\n",
    "URL_REG = \"https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/spotify_data%20clean.csv\"\n",
    "URL_CLUST = \"https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/Most_Streamed_Spotify_Songs_2024.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SÄ±nÄ±flandÄ±rma GÃ¶revi (Classification)\n",
    "**AmaÃ§:** ÅžarkÄ±nÄ±n ses Ã¶zelliklerine (dans edilebilirlik, enerji vb.) bakarak 'PopÃ¼ler' olup olmadÄ±ÄŸÄ±nÄ± tahmin etmek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Veriyi YÃ¼kle\n",
    "df_class = load_data_from_github('dataset.csv', URL_CLASS)\n",
    "print(f\"Veri Seti Boyutu: {df_class.shape}\")\n",
    "\n",
    "# 2. Hedef DeÄŸiÅŸkenin OluÅŸturulmasÄ±\n",
    "# PopÃ¼laritesi 50'den bÃ¼yÃ¼k olanlar '1' (PopÃ¼ler), diÄŸerleri '0' (PopÃ¼ler DeÄŸil)\n",
    "df_class['is_popular'] = (df_class['popularity'] > 50).astype(int)\n",
    "\n",
    "# 3. Gereksiz SÃ¼tunlarÄ±n Temizlenmesi\n",
    "# ID, Ä°sim gibi makine Ã¶ÄŸrenmesine katkÄ±sÄ± olmayan sÃ¼tunlar Ã§Ä±karÄ±lÄ±r.\n",
    "cols_to_drop = ['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'track_genre']\n",
    "X = df_class.drop(columns=[c for c in cols_to_drop if c in df_class.columns])\n",
    "X = X.drop(columns=['is_popular']) # Hedef deÄŸiÅŸkeni Ã¶zelliklerden ayÄ±r\n",
    "y = df_class['is_popular']\n",
    "\n",
    "# Explicit sÃ¼tununu sayÄ±sal hale getir\n",
    "if 'explicit' in X.columns:\n",
    "    X['explicit'] = X['explicit'].astype(int)\n",
    "\n",
    "print(\"Ã–znitelik SeÃ§imi TamamlandÄ±.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veri Ã–n Ä°ÅŸleme ve Dengesizlik Giderme\n",
    "Eksik veriler doldurulur, veriler Ã¶lÃ§eklenir ve `RandomUnderSampler` ile sÄ±nÄ±f dengesizliÄŸi giderilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EÄŸitim ve Test AyrÄ±mÄ± (%80 EÄŸitim, %20 Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Pipeline TanÄ±mlama\n",
    "# SayÄ±sal veriler iÃ§in: Eksik verileri doldur -> StandartlaÅŸtÄ±r (Scale)\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_features),\n",
    "        ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Dengesiz Veri YÃ¶netimi (Undersampling)\n",
    "# PopÃ¼ler olmayan ÅŸarkÄ± sayÄ±sÄ± Ã§ok fazla olduÄŸu iÃ§in, popÃ¼ler olanlarla eÅŸitliyoruz.\n",
    "try:\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    # Pipeline uygulamadan Ã¶nce veriyi dengelemek en saÄŸlÄ±klÄ±sÄ±dÄ±r\n",
    "    print(f\"Resampling Ã–ncesi SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±: {np.bincount(y_train)}\")\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    print(f\"Resampling SonrasÄ± SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±: {np.bincount(y_train_resampled)}\")\n",
    "    \n",
    "    X_train = X_train_resampled\n",
    "    y_train = y_train_resampled\n",
    "except ImportError:\n",
    "    print(\"[UYARI] imblearn kÃ¼tÃ¼phanesi bulunamadÄ±, orjinal veri ile devam ediliyor.\")\n",
    "\n",
    "# Veriyi DÃ¶nÃ¼ÅŸtÃ¼r (Fit & Transform)\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "print(\"Ã–n iÅŸleme tamamlandÄ±.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model EÄŸitimi ve DeÄŸerlendirme\n",
    "Random Forest modeli eÄŸitilir ve sonuÃ§lar raporlanÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model EÄŸitimi: Random Forest Classifier\n",
    "print(\"Random Forest modeli eÄŸitiliyor...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Tahmin\n",
    "y_pred = rf_model.predict(X_test_processed)\n",
    "\n",
    "# SonuÃ§lar\n",
    "print(\"--- SÄ±nÄ±flandÄ±rma SonuÃ§larÄ± ---\")\n",
    "print(f\"DoÄŸruluk (Accuracy): {accuracy_score(y_test, y_pred):.4f}\")\n",
    "# DetaylÄ± Rapor (Precision, Recall, F1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regresyon GÃ¶revi (Regression)\n",
    "**AmaÃ§:** ÅžarkÄ±nÄ±n ve sanatÃ§Ä±nÄ±n metadatalarÄ±nÄ± kullanarak 0-100 arasÄ±ndaki 'PopÃ¼lerlik PuanÄ±nÄ±' net olarak tahmin etmek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Veriyi YÃ¼kle\n",
    "df_reg = load_data_from_github('spotify_data clean.csv', URL_REG)\n",
    "print(f\"Regresyon Veri Seti Boyutu: {df_reg.shape}\")\n",
    "\n",
    "# 2. Ã–zellik SeÃ§imi\n",
    "target_col = 'track_popularity'\n",
    "# Metin tabanlÄ± ve gereksiz sÃ¼tunlarÄ± Ã§Ä±karÄ±yoruz\n",
    "cols_to_drop = ['track_id', 'track_name', 'artist_name', 'album_id', 'album_name', 'album_release_date', 'artist_genres']\n",
    "X_reg = df_reg.drop(columns=[c for c in cols_to_drop if c in df_reg.columns])\n",
    "X_reg = X_reg.drop(columns=[target_col])\n",
    "y_reg = df_reg[target_col]\n",
    "\n",
    "# 3. Pipeline HazÄ±rlÄ±ÄŸÄ±\n",
    "numeric_features_reg = X_reg.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features_reg = X_reg.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "reg_preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_features_reg),\n",
    "    ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features_reg)\n",
    "])\n",
    "\n",
    "# EÄŸitim/Test AyrÄ±mÄ±\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model EÄŸitimi: Random Forest Regressor\n",
    "print(\"Regresyon Modeli EÄŸitiliyor (Bu iÅŸlem birkaÃ§ saniye sÃ¼rebilir)...\")\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Pipeline OluÅŸtur (Ã–n Ä°ÅŸleme + Model)\n",
    "reg_pipeline = Pipeline(steps=[('preprocessor', reg_preprocessor), ('regressor', rf_reg)])\n",
    "reg_pipeline.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Tahmin ve DeÄŸerlendirme\n",
    "y_pred_reg = reg_pipeline.predict(X_test_reg)\n",
    "\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "\n",
    "print(f\"--- Regresyon SonuÃ§larÄ± ---\")\n",
    "print(f\"R2 Skoru (BaÅŸarÄ± OranÄ±): {r2:.4f}\")\n",
    "print(f\"RMSE (Ortalama Hata PayÄ±): {rmse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KÃ¼meleme GÃ¶revi (Clustering)\n",
    "**AmaÃ§:** ÅžarkÄ±larÄ± dinlenme sayÄ±larÄ±na (Streams) ve sosyal medya etkileÅŸimlerine (TikTok/YouTube) gÃ¶re gruplara ayÄ±rmak.\n",
    "Bu veri seti etiketli deÄŸildir (Unsupervised Learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Veriyi YÃ¼kle\n",
    "filename_clust = 'Most_Streamed_Spotify_Songs_2024.csv'\n",
    "df_clust = load_data_from_github(filename_clust, URL_CLUST)\n",
    "\n",
    "# 2. Veri TemizliÄŸi\n",
    "# SayÄ±sal olmasÄ± gereken sÃ¼tunlardaki virgÃ¼lleri (Ã¶rn: \"1,000\") temizliyoruz.\n",
    "cols_to_clean = ['Spotify Streams', 'Spotify Playlist Count', 'YouTube Views', 'TikTok Views']\n",
    "for col in cols_to_clean:\n",
    "    if col in df_clust.columns and df_clust[col].dtype == object:\n",
    "        df_clust[col] = pd.to_numeric(df_clust[col].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Sadece sayÄ±sal sÃ¼tunlarÄ± al ve eksikleri 0 ile doldur\n",
    "X_clust = df_clust[cols_to_clean].fillna(0)\n",
    "\n",
    "# Veri Ã§ok bÃ¼yÃ¼kse hÄ±z iÃ§in Ã¶rneklem al\n",
    "if len(X_clust) > 5000:\n",
    "    X_clust = X_clust.iloc[:5000]\n",
    "\n",
    "# 3. Ã–lÃ§ekleme (Clustering iÃ§in kritiktir)\n",
    "scaler_clust = StandardScaler()\n",
    "X_clust_scaled = scaler_clust.fit_transform(X_clust)\n",
    "\n",
    "# 4. K-Means Modelleme\n",
    "print(\"K-Means KÃ¼meleme Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±yor (K=3)...\")\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X_clust_scaled)\n",
    "\n",
    "# 5. BaÅŸarÄ± MetriÄŸi (Silhouette Score)\n",
    "sil_score = silhouette_score(X_clust_scaled, labels)\n",
    "print(f\"--- KÃ¼meleme Sonucu ---\")\n",
    "print(f\"Silhouette Skoru: {sil_score:.4f} (1'e ne kadar yakÄ±nsa o kadar iyi ayrÄ±ÅŸmÄ±ÅŸ demektir)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}