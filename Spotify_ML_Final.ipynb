{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine Öğrenmesi Dönem Ödevi Projesi Raporu (F2025)\n",
    "\n",
    "**Öğrenci Adı Soyadı:** Firuze Eroğlu  \n",
    "**Öğrenci No:** 201613709044  \n",
    "**Teslim Tarihi:** 14.12.2025  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Veri Seti Tanıtımı\n",
    "\n",
    "Bu projede üç farklı makine öğrenmesi problemi için, müzik endüstrisinin en büyük platformu Spotify'dan elde edilen gerçek dünya verileri kullanılmıştır. Veri setleri Kaggle platformundan \"Open Access\" (Açık Erişim) lisansıyla temin edilmiştir. Aşağıda her bir veri setinin kaynağı, içeriği ve proje kapsamındaki kullanım amacı detaylandırılmıştır.\n",
    "\n",
    "### 1.1. Sınıflandırma Veri Seti: Spotify Tracks Dataset\n",
    "*   **Veri Kaynağı Linki:** [Kaggle - Spotify Tracks Dataset](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)\n",
    "*   **Veri Seti Tanımı:** Bu veri seti, Spotify üzerindeki 125 farklı müzik türünden yaklaşık 114.000 şarkıyı kapsamaktadır. Her bir satır bir şarkıyı temsil eder ve şarkıya ait teknik ses özelliklerini (audio features) içerir.\n",
    "*   **Problem ve Tahmin Hedefi:**\n",
    "    *   **Problem:** Müzik endüstrisinde bir şarkının \"Hit\" olup olmayacağını, şarkı henüz piyasaya çıkmadan sadece ses analizine dayanarak öngörmek büyük bir ticari değer taşır.\n",
    "    *   **Hedef:** Şarkının `danceability` (dans edilebilirlik), `energy` (enerji), `loudness` (ses şiddeti), `acousticness` gibi teknik ses özniteliklerini kullanarak, şarkının **\"Popüler\"** (Popularity > 50) olup olmadığını sınıflandırmaya çalışıyoruz. Bu, **Binary Classification** (İkili Sınıflandırma) problemidir.\n",
    "*   **Kullanılan Öznitelikler (Features):**\n",
    "    *   `danceability`: Tempo, ritim kararlılığı ve vuruş gücüne göre şarkının dansa uygunluğu (0.0 - 1.0).\n",
    "    *   `energy`: Şarkının yoğunluk ve aktivite ölçümü. Hızlı, gürültülü şarkılar 1.0'a yakındır.\n",
    "    *   `valence`: Şarkının taşıdığı müzikal pozitiflik (mutluluk/hüzün) düzeyi.\n",
    "    *   `instrumentalness`: Şarkının ne kadar enstrümantal olduğu (vokal olup olmadığı).\n",
    "    *   `duration_ms`: Şarkının milisaniye cinsinden süresi.\n",
    "\n",
    "### 1.2. Regresyon Veri Seti: Spotify Global Music Dataset\n",
    "*   **Veri Kaynağı Linki:** [Kaggle - Spotify Global Music Dataset 2009-2025](https://www.kaggle.com/datasets/wardabilal/spotify-global-music-dataset-20092025?select=spotify_data+clean.csv) (Kullanılan dosya: `spotify_data clean.csv`)\n",
    "*   **Veri Seti Tanımı:** 2009-2025 yılları arasındaki küresel müzik trendlerini içeren, temizlenmiş ve yapılandırılmış bir veri setidir. Yaklaşık 8.500 örnek içermektedir.\n",
    "*   **Problem ve Tahmin Hedefi:**\n",
    "    *   **Problem:** Bir şarkının başarısı sadece ses özelliklerine mi bağlıdır, yoksa sanatçının şöhreti ve albümün yapısı daha mı etkilidir?\n",
    "    *   **Hedef:** Şarkının ve sanatçının metadatalarını (metadata) kullanarak, şarkının Spotify üzerindeki **Popülerlik Puanını (0 ile 100 arasında sürekli bir değer)** sayısal olarak tahmin etmek. Bu, bir **Regresyon** (Kestirim) problemidir.\n",
    "*   **Kullanılan Öznitelikler (Features):**\n",
    "    *   `artist_popularity`: Şarkıyı söyleyen sanatçının genel popülerlik skoru.\n",
    "    *   `artist_followers`: Sanatçının takipçi sayısı (Sanatçının hayran kitlesi).\n",
    "    *   `album_total_tracks`: Şarkının bulunduğu albümdeki toplam şarkı sayısı.\n",
    "    *   `album_type`: Albümün türü (Single, Album, Compilation).\n",
    "    *   `explicit`: Şarkının sansürlü/küfürlü içerik barındırıp barındırmadığı.\n",
    "\n",
    "### 1.3. Kümeleme Veri Seti: Most Streamed Spotify Songs 2024\n",
    "*   **Veri Kaynağı Linki:** [Kaggle - Most Streamed Spotify Songs 2024](https://www.kaggle.com/datasets/nelgiriyewithana/most-streamed-spotify-songs-2024)\n",
    "*   **Veri Seti Tanımı:** 2024 yılının en çok dinlenen şarkılarını ve bu şarkıların farklı platformlardaki (Spotify, TikTok, YouTube, vb.) etkileşim sayılarını içeren güncel bir veri setidir.\n",
    "*   **Problem ve Analiz Hedefi:**\n",
    "    *   **Problem:** Milyonlarca dinlenen şarkılar arasında gizli örüntüler veya farklı başarı profilleri var mıdır? (Örneğin: \"TikTok sayesinde ünlü olanlar\" vs \"Organik hitler\").\n",
    "    *   **Hedef:** Veri setindeki şarkıların **Etiketsiz** (Unsupervised) olarak benzerliklerine göre gruplandırılmasıdır. Şarkıları dinlenme sayıları, çalma listelerine eklenme sıklığı ve sosyal medya etkileşimlerine göre **Segmentlere (Kümeler)** ayırarak, müzik dünyasındaki farklı başarı tiplerini analiz etmeyi hedefliyoruz.\n",
    "*   **Kullanılan Öznitelikler (Features):**\n",
    "    *   `Spotify Streams`: Toplam dinlenme sayısı.\n",
    "    *   `Spotify Playlist Count`: Şarkının kaç farklı çalma listesine eklendiği.\n",
    "    *   `TikTok Views`: Şarkının TikTok platformundaki görüntülenme sayısı.\n",
    "    *   `YouTube Views`: Şarkının YouTube görüntülenme sayısı.\n",
    "    *   `AirPlay Spins`: Radyolarda çalınma sayısı.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Uygulanan Yöntemler ve Ön İşleme\n",
    "\n",
    "### 2.1. Veri Ön İşleme (Preprocessing)\n",
    "Tüm veri setleri için aşağıdaki standart adımlar uygulanmıştır:\n",
    "*   **Eksik Veriler (Missing Values):** Sayısal sütunlardaki eksik veriler medyan ile, kategorik veriler sabit değer veya en sık görülen değer ile dolduruldu ('SimpleImputer').\n",
    "*   **Özellik Ölçekleme (Scaling):** Tüm algoritmaların (özellikle K-Means ve Logistic Regression) performansını artırmak için `StandardScaler` ile veriler ölçeklendi (Ortalama=0, Varyans=1).\n",
    "*   **Kategorik Dönüşüm:** `OneHotEncoder` kullanılarak 'album_type' ve 'explicit' gibi kategorik veriler sayısal matrise dönüştürüldü.\n",
    "*   **Dengesiz Veri Çözümü (Undersampling):** Sınıflandırma görevinde, \"Popüler Olmayan\" şarkıların sayısı \"Popüler\" olanlardan çok daha fazlaydı. Modelin çoğunluk sınıfına meyletmesini önlemek için **RandomUnderSampler** kullanılarak çoğunluk sınıfındaki veri sayısı azaltıldı ve iki sınıf eşitlendi. Bu, özellikle 'Recall' değerini artırmak için kritik bir adımdı.\n",
    "*   **Aykırı Değer Analizi (Outlier Handling):** Regresyon görevinde IQR (Interquartile Range) yöntemi kullanılarak veri setindeki aşırı uç değerler temizlendi.\n",
    "*   **Veri Ayrımı ve Doğrulama (Validation):** Tüm görevlerde veri seti `%80 Eğitim - %20 Test` oranında ve `stratify` (sınıf dengesini koruyarak) parametresiyle ayrıldı. Ayrıca, **Random Forest** modeli eğitilirken **3-Katlı Çapraz Doğrulama (3-Fold Cross-Validation)** (\"k-fold cross val\") kullanıldı. Bu yöntem, modelin veriye aşırı uyum (overfitting) sağlamasını engelledi ve sonuçların güvenilirliğini artırdı.\n",
    "\n",
    "### 2.2. Algoritma Seçimi\n",
    "*   **Sınıflandırma:** Logistic Regression, Random Forest Classifier, XGBoost. (RF için `RandomizedSearchCV` ile optimizasyon yapıldı).\n",
    "*   **Regresyon:** Linear Regression, Random Forest Regressor, Gradient Boosting.\n",
    "*   **Kümeleme:** K-Means, MiniBatch K-Means, DBSCAN. (K değeri Silhouette analizi ile belirlendi).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Sonuçlar ve Metrikler\n",
    "\n",
    "### 3.1. Sınıflandırma Sonuçları ve Görseller\n",
    "Sınıflandırma görevinde \"Popülerlik\" tahmini için modellerin performansı karşılaştırılmıştır.\n",
    "\n",
    "#### **A. Model Performansı ve Karşılaştırma**\n",
    "Aşağıdaki grafik, üç modelin \"Accuracy\" (Doğruluk) ve \"Recall\" (Yakama) oranlarını göstermektedir.\n",
    "![Model Karşılaştırması](model_comparison_chart.png)\n",
    "\n",
    "*   **Yorum:** Grafikte görüldüğü üzere, **Random Forest (Optimized)** modeli en dengeli performansı sergilemiştir. Hiperparametre optimizasyonu öncesi \"Popüler\" sınıfını yakalamakta zorlanan model, optimizasyon ve undersampling sonrası her iki sınıfı da %75 civarında başarıyla tahmin edebilmiştir.\n",
    "\n",
    "#### **B. Hata Matrisi (Confusion Matrix)**\n",
    "Modelin nerede hata yaptığını anlamak için Random Forest modelinin Karmaşıklık Matrisi (Confusion Matrix) aşağıdadır:\n",
    "![Confusion Matrix](cm_Random_Forest_Optimized.png)\n",
    "\n",
    "*   **Yorum:** Matris incelendiğinde, modelin \"Popüler Olmayan\" (0) şarkıların büyük çoğunluğunu doğru bildiği, ancak \"Popüler\" (1) şarkıların bir kısmını hala kaçırdığı görülmektedir. Müzik başarısının sadece ses özelliklerine bağlı olmaması (pazarlama, bütçe vb.) bu hatanın doğal sebebidir.\n",
    "\n",
    "#### **C. Model Açıklanabilirliği (SHAP Analizi)**\n",
    "Modelin *neden* bu kararı verdiğini anlamak için XGBoost modeli üzerinde SHAP analizi yapılmıştır:\n",
    "![SHAP Analizi](shap_summary.png)\n",
    "\n",
    "*   **Detaylı Analiz:**\n",
    "    1.  **Loudness (Ses Şiddeti):** En belirleyici özellik. Grafikte sağa doğru (yüksek değerler) kırmızı noktaların yoğunlaşması, **daha gürültülü/yüksek sesli şarkıların popüler olma ihtimalinin daha yüksek olduğunu** göstermektedir.\n",
    "    2.  **Acousticness:** Düşük akustik (daha elektronik/üretilmiş) şarkılar popülerlikle pozitif korelasyon göstermektedir.\n",
    "    3.  **Duration:** Çok uzun şarkılar popülerlik şansını düşürmektedir.\n",
    "\n",
    "### 3.2. Regresyon Sonuçları ve Görseller\n",
    "Şarkı popülaritesini (0-100) tahmin etme başarısı:\n",
    "\n",
    "#### **A. Tahmin Başarısı (Gerçek vs Tahmin)**\n",
    "Random Forest modelinin tahminleri ile gerçek değerlerin karşılaştırması:\n",
    "![Regresyon Tahminleri](reg_pred_Random_Forest.png)\n",
    "\n",
    "*   **Yorum:** İdeal durumda tüm noktaların kırmızı köşegen çizgi üzerinde olması gerekirdi. Grafikteki saçılım, modelin genel trendi yakaladığını (R² ~ 0.24) ancak birebir puan tahmininde sapmalar yaşadığını gösterir. RMSE (Hata Kareler Ortalaması) yaklaşık 20 puandır; yani model bir şarkıya \"60 puan\" dediğinde, gerçek puan 40 veya 80 olabilir.\n",
    "\n",
    "#### **B. Özellik Önemi (Feature Importance - Feature Selection)**\n",
    "Hangi faktörler bir şarkının puanını artırır?\n",
    "![Feature Importance](regression_feature_importance.png)\n",
    "\n",
    "*   **Kritik Bulgular:**\n",
    "    *   **Artist Popularity (Sanatçı Popülerliği):** Grafikteki en uzun çubuktur. Bu, şarkının *nasıl* duyulduğundan ziyade *kimin* söylediğinin başarıda en büyük etken olduğunu kanıtlar.\n",
    "    *   **Artist Followers:** İkinci sırada sanatçının hayran kitlesi gelmektedir.\n",
    "    *   **Explicit (Sansür):** Şarkının küfürlü olup olmamasının popülerlik üzerinde marjinal bir etkisi vardır.\n",
    "\n",
    "### 3.3. Kümeleme Sonuçları ve Görseller (PCA ve Segmentasyon)\n",
    "Şarkıların dinlenme ve etkileşim sayılarına göre gruplandırılması:\n",
    "\n",
    "#### **A. Küme Dağılımı (K-Means, K=2) ve PCA**\n",
    "Veri seti PCA (Principal Component Analysis) ile 2 boyuta indirgenmiş ve kümeler görselleştirilmiştir:\n",
    "![K-Means Kümeleme](clustering_K_Means_K2.png)\n",
    "\n",
    "*   **Küme Analizi:**\n",
    "    *   **Küme 0 (Mor):** Düşük ve orta seviye dinlenmeye sahip şarkıların oluşturduğu ana gövde. Şarkıların %90'ı buradadır.\n",
    "    *   **Küme 1 (Sarı):** \"Süper Hit\" şarkılar. Sayıları azdır ancak grafikte diğerlerinden net bir şekilde ayrışmışlardır.\n",
    "\n",
    "#### **B. Platform Etkileşimi (Spotify vs TikTok)**\n",
    "Şarkıların Spotify dinlenmeleri ile TikTok görüntülenmeleri arasındaki ilişki:\n",
    "![Scatter Plot](clustering_scatter_streams.png)\n",
    "\n",
    "*   **Yorum:** Grafikte, TikTok'ta çok görüntülenen şarkıların (Y ekseni yüksek), Spotify'da da çok dinlendiği (X ekseni yüksek) bariz bir **pozitif korelasyon** görülmektedir. Bu, sosyal medya viralitesinin müzik başarısındaki kilit rolünü doğrular.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Sonuçların Özeti (Summary of Results)\n",
    "\n",
    "Kodların son çalıştırılması neticesinde elde edilen başarı metrikleri ve süreler aşağıdaki tabloda özetlenmiştir:\n",
    "\n",
    "| Görev | Model | Ana Metrik | Değer | Eğitim Süresi (sn) |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Sınıflandırma** | Logistic Regression | Accuracy | %56 | 0.04 sn |\n",
    "| | Random Forest (Opt) | Accuracy | %74 | 100.06 sn |\n",
    "| | XGBoost | Accuracy | %74 | 2.63 sn |\n",
    "| **Regresyon** | Linear Regression | R2 Score | 0.22 | 0.002 sn |\n",
    "| | Random Forest | R2 Score | 0.24 | 0.71 sn |\n",
    "| | Gradient Boosting | R2 Score | 0.24 | 0.50 sn |\n",
    "| **Kümeleme** | K-Means (K=2) | Silhouette | 0.45 | 0.003 sn |\n",
    "| | DBSCAN | Silhouette | 0.09 | 0.06 sn |\n",
    "\n",
    "*(Not: Tablodaki değerler çalışılan bilgisayarın donanımına göre küçük değişiklikler gösterebilir.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Tartışma ve Yorumlar (Discussion)\n",
    "\n",
    "Proje sonuçlarında elde edilen teknik bulguların yorumlanması:\n",
    "\n",
    "1.  **Dengesiz Veri Yönetimi:** Sınıflandırma görevinde, veri seti dengesiz olduğu için başlangıçta model sadece çoğunluk sınıfını (Popüler Olmayan) tahmin ediyordu. `Undersampling` tekniği uygulandıktan sonra doğruluk (accuracy) düşmüş gibi görünse de, aslında *Recall* (Duyarlılık) metriği ciddi oranda artarak modelin \"Popüler\" şarkıları yakalama yeteneği kazandırıldı. Bu, gerçek hayatta \"Hit Şarkı\" avcılığı için daha doğru bir yaklaşımdır.\n",
    "2.  **Özniteliklerin Gücü (Feature Relevance):** Regresyon analizi net bir şekilde gösterdi ki, bir şarkının popülerliği, o şarkının müzikal yapısından (bpm, key, mode) ziyade, sanatçının mevcut şöhreti (`artist_popularity`) ile ilişkilidir. Bu durum, müzik endüstrisinde \"yıldız gücünün\" içerikten daha baskın olabileceği tezini destekler.\n",
    "3.  **Kümeleme Yapısı:** Müzik piyasası homojen bir dağılım göstermez. K-Means ve Silhouette analizi, verinin en iyi 2 kümeye ayrıldığını gösterdi: \"Mega Hit'ler\" ve \"Diğerleri\". Bu, endüstrideki gelir dağılımı eşitsizliğine (Pareto Prensibi) işaret eder.\n",
    "4.  **Cross-Validation Etkisi:** Model eğitiminde sadece `Train-Test Split` yerine `Cross-Validation` kullanılması, özellikle küçük veri setlerinde (Regresyon verimiz 8.500 satırdı) modelin kararlılığını artırdı. Tek bir test setine bağlı kalmak yerine verinin farklı parçalarında test yapılması, elde ettiğimiz R² skorunun şans eseri olmadığını doğruladı.\n",
    "5.  **Model Performansları:** Ağaç tabanlı modellerin (Random Forest ve XGBoost), doğrusal modellere (Linear/Logistic Regression) göre karmaşık ilişkileri modellemede daha başarılı olduğu gözlemlendi. Ancak bu modellerin eğitimi ve hiperparametre optimizasyonu (GridSearchCV) çok daha uzun sürdü (~100 sn vs ~0.1 sn).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Kazanımlar / Öğrenilenler (Learnings)\n",
    "\n",
    "Bu dönem ödevi projesi kapsamında şunlar öğrenilmiştir:\n",
    "*   **Veri Kalitesinin Önemi:** Gerçek dünya verilerinin \"temiz\" olmadığını, eksik verilerin (missing values) ve gürültünün (noise) model başarısını doğrudan etkilediği görüldü.\n",
    "*   **Metriklerin Doğru Okunması:** Sadece `Accuracy`'ye bakmanın yanıltıcı olabileceği, dengesiz veri setlerinde `Recall` ve `F1-Score`'un hayati olduğu anlaşıldı.\n",
    "*   **İş Bilgisi (Domain Knowledge):** Veri biliminde sadece kod yazmanın yetmediği, verinin ait olduğu alanın (müzik endüstrisi) dinamiklerini bilmenin (örn: TikTok'un etkisi) analiz başarısını artırdığı fark edildi.\n",
    "*   **AI ve Otomasyon:** Hiperparametre optimizasyonu ve özellik seçimi gibi süreçlerin yapay zeka ve otomasyon araçlarıyla ne kadar hızlandırılabileceği deneyimlendi.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Akademik Dürüstlük ve Yapay Zekâ Kullanımı Beyanı\n",
    "\n",
    "Bu ödevin hazırlanmasında;\n",
    "*   **Kodlama:** Python scriptlerinin (`pandas`, `scikit-learn`, `imblearn` kullanımı) hazırlanması, hata ayıklama (debugging) ve grafik çizdirme süreçlerinde **AI Asistanı** (Antigravity/Gemini) desteği alınmıştır. AI, kodun iskeletini oluşturmada ve syntax hatalarını düzeltmede kullanılmıştır.\n",
    "*   **Strateji:** Dengesiz veri setlerinde `recall` sorununu çözmek için `undersampling` yönteminin seçilmesi ve uygulanmasında AI rehberliğinden faydalanılmıştır. Ancak veri setlerinin seçimi ve problemin kurgulanması tarafımca yapılmıştır.\n",
    "*   **Yorumlama:** Elde edilen teknik çıktıların (R² skoru, SHAP değerleri, Recall dengesi, Confusion Matrix yorumları) analizi ve raporlanması, kendi cümlelerimle ve derste öğrenilen bilgiler ışığında şahsım tarafından yapılmıştır.\n",
    "\n",
    "---\n",
    "\n",
    "### Ek 1: Çalışma Ortamı (Donanım Özellikleri)\n",
    "Proje aşağıdaki donanım özelliklerine sahip bilgisayarda çalıştırılmıştır:\n",
    "*   **Model:** Monster Abra A5 V15.7\n",
    "*   **İşletim Sistemi:** Windows\n",
    "*   **İşlemci (CPU):** Intel Core i5 10. Nesil\n",
    "*   **Bellek (RAM):** 16 GB (DDR4)\n",
    "*   **Ekran Kartı (GPU):** NVIDIA GeForce GTX 1650 Ti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task\n",
    "Kodlar aşağıdadır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import time\n",
    "\n",
    "print(\"Veri Seti Yükleniyor (Spotify Dataset)...\")\n",
    "try:\n",
    "    # Colab & Local Data Loading\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    filename = 'dataset.csv'\n",
    "    url = 'https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/dataset.csv'\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        print(f'Colab detected: Downloading {filename} from GitHub...')\n",
    "        df = pd.read_csv(url)\n",
    "    print(f\"Veri seti boyutu: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: 'dataset.csv' bulunamadı.\")\n",
    "    exit()\n",
    "\n",
    "target_col = 'is_popular'\n",
    "df[target_col] = (df['popularity'] > 50).astype(int)\n",
    "print(f\"Yeni hedef değişken: {target_col}\")\n",
    "\n",
    "cols_to_drop = ['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'track_genre']\n",
    "feature_cols = [c for c in df.columns if c not in cols_to_drop and c != target_col]\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "print(f\"Kullandığım özellikler:\\n{X.columns.tolist()}\")\n",
    "\n",
    "if 'explicit' in X.columns:\n",
    "    X['explicit'] = X['explicit'].astype(int)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train boyutu: {X_train.shape}, Sınıf Dağılımı: {np.bincount(y_train)}\")\n",
    "\n",
    "try:\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    print(f\"Resampled train boyutu: {X_train_resampled.shape}, Sınıf Dağılımı: {np.bincount(y_train_resampled)}\")\n",
    "    X_train = X_train_resampled\n",
    "    y_train = y_train_resampled\n",
    "except ImportError:\n",
    "    print(\"UYARI: 'imblearn' kütüphanesi yok. Manuel undersampling uyguluyorum...\")\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    minority_count = y_train.value_counts().min()\n",
    "    df_0 = train_df[train_df[target_col] == 0].sample(minority_count, random_state=42)\n",
    "    df_1 = train_df[train_df[target_col] == 1]\n",
    "    balanced_df = pd.concat([df_0, df_1])\n",
    "    X_train = balanced_df.drop(columns=[target_col])\n",
    "    y_train = balanced_df[target_col]\n",
    "    print(f\"Manuel Resampled Boyut: {X_train.shape}\")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"\\nAykırı değerleri (Outliers) inceliyorum...\")\n",
    "try:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if 'duration_ms' in df.columns:\n",
    "        sns.boxplot(x=df['duration_ms'] / 60000)\n",
    "        plt.title('Şarkı Süresi Dağılımı (Dakika)')\n",
    "        plt.xlabel('Süre (dk)')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if 'danceability' in df.columns:\n",
    "        sns.histplot(df['danceability'], bins=30, kde=True)\n",
    "        plt.title('Dans Edilebilirlik Dağılımı')\n",
    "    else:\n",
    "        sns.histplot(df.iloc[:, 0], bins=30)\n",
    "        plt.title('Birinci Sütun Dağılımı')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('classification_outliers.png')\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Grafik hatası: {e}\")\n",
    "\n",
    "print(\"\\nModelleri eğitiyorum...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_prob = model.predict_proba(X_te)[:, 1] if hasattr(model, \"predict_proba\") else np.zeros(len(y_te))\n",
    "\n",
    "    acc = accuracy_score(y_te, y_pred)\n",
    "    prec = precision_score(y_te, y_pred, average='weighted')\n",
    "    rec = recall_score(y_te, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_te, y_pred, average='weighted')\n",
    "\n",
    "    report_dict = classification_report(y_te, y_pred, output_dict=True)\n",
    "    recall_0 = report_dict['0']['recall']\n",
    "    recall_1 = report_dict['1']['recall']\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_te, y_prob)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "\n",
    "    print(f\"--- {name} Sonuçları ---\")\n",
    "    print(f\"Bütün: Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "    print(f\"Recall (Popüler Olmayan): {recall_0:.4f}\")\n",
    "    print(f\"Recall (Popüler): {recall_1:.4f}\")\n",
    "    print(classification_report(y_te, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_te, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('Gerçek')\n",
    "    plt.xlabel('Tahmin')\n",
    "    plt.savefig(f'cm_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        'Model': name, 'Accuracy': acc, 'Precision': prec,\n",
    "        'Recall': rec, 'F1': f1, 'AUC': auc,\n",
    "        'Recall_0': recall_0, 'Recall_1': recall_1,\n",
    "        'Time (s)': train_time\n",
    "    }\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "results.append(evaluate_model(\"Logistic Regression\", lr_model, X_train_processed, y_train, X_test_processed, y_test))\n",
    "\n",
    "print(\"\\nRandom Forest için en iyi parametreleri arıyorum...\")\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_search = time.time()\n",
    "random_search.fit(X_train_processed, y_train)\n",
    "print(f\"Bulunan en iyi parametreler: {random_search.best_params_}\")\n",
    "print(f\"Arama süresi: {time.time() - start_search:.2f} sn\")\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "results.append(evaluate_model(\"Random Forest (Optimized)\", best_rf, X_train_processed, y_train, X_test_processed, y_test))\n",
    "\n",
    "print(\"\\nXGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "results.append(evaluate_model(\"XGBoost\", xgb_model, X_train_processed, y_train, X_test_processed, y_test))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nKarşılaştırma Tablosu:\")\n",
    "print(results_df)\n",
    "results_df.to_csv('model_comparison_classification.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "results_df.set_index('Model')[['Accuracy', 'Recall_1', 'AUC']].plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performansı (Accuracy vs Popüler Şarkı Yakalama)')\n",
    "plt.ylabel('Skor')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_chart.png')\n",
    "\n",
    "print(\"\\nSHAP ile model analizi...\")\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(xgb_model)\n",
    "    X_shap = X_test_processed[:100].toarray() if hasattr(X_test_processed, \"toarray\") else X_test_processed[:100]\n",
    "    shap_values = explainer.shap_values(X_shap)\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_shap, show=False, feature_names=numeric_features.tolist())\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_summary.png')\n",
    "except Exception as e:\n",
    "    print(f\"SHAP hatası: {e}\")\n",
    "\n",
    "print(\"\\nSınıflandırma işlemi bitti.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task\n",
    "Kodlar aşağıdadır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "print(\"Veri Seti Yükleniyor (Spotify Data)...\")\n",
    "try:\n",
    "    # Colab & Local Data Loading\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    filename = 'spotify_data clean.csv'\n",
    "    url = 'https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/spotify_data%20clean.csv'\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        print(f'Colab detected: Downloading {filename} from GitHub...')\n",
    "        df = pd.read_csv(url)\n",
    "    print(f\"Veri seti boyutu: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: 'spotify_data clean.csv' bulunamadı.\")\n",
    "    exit()\n",
    "\n",
    "target_col = 'track_popularity'\n",
    "\n",
    "cols_to_drop = ['track_id', 'track_name', 'artist_name', 'album_id', 'album_name', 'album_release_date', 'artist_genres', target_col]\n",
    "\n",
    "X = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"Kullandığım özellikler:\", X.columns.tolist())\n",
    "\n",
    "print(\"\\nVeri ön işleme adımları...\")\n",
    "\n",
    "print(\"\\nVeri ön işleme adımları...\")\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "Q1 = df[numeric_features].quantile(0.25)\n",
    "Q3 = df[numeric_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "condition = ~((df[numeric_features] < (Q1 - 3 * IQR)) | (df[numeric_features] > (Q3 + 3 * IQR))).any(axis=1)\n",
    "original_len = len(df)\n",
    "df_clean = df[condition]\n",
    "X = df_clean.drop(columns=[c for c in cols_to_drop if c in df_clean.columns])\n",
    "y = df_clean[target_col]\n",
    "\n",
    "print(f\"Outlier temizliğinden sonra kalan veri: {len(df_clean)} (Atılan: {original_len - len(df_clean)})\")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_regressor(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    y_pred_tr = model.predict(X_tr)\n",
    "    y_pred_te = model.predict(X_te)\n",
    "\n",
    "    r2 = r2_score(y_te, y_pred_te)\n",
    "    rmse = np.sqrt(mean_squared_error(y_te, y_pred_te))\n",
    "    mae = mean_absolute_error(y_te, y_pred_te)\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, Süre: {train_time:.2f}sn\")\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_te, y_pred_te, alpha=0.3)\n",
    "    plt.plot([y_te.min(), y_te.max()], [y_te.min(), y_te.max()], 'r--')\n",
    "    plt.xlabel('Gerçek Değerler')\n",
    "    plt.ylabel('Tahminler')\n",
    "    plt.title(f'{name}: Gerçek vs Tahmin')\n",
    "    plt.savefig(f'reg_pred_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return {'Model': name, 'R2': r2, 'RMSE': rmse, 'MAE': mae, 'Training Time': train_time}\n",
    "\n",
    "lr = LinearRegression()\n",
    "results.append(evaluate_regressor(\"Linear Regression\", lr, X_train_scaled, y_train, X_test_scaled, y_test))\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "results.append(evaluate_regressor(\"Random Forest\", rf, X_train_scaled, y_train, X_test_scaled, y_test))\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "results.append(evaluate_regressor(\"Gradient Boosting\", gb, X_train_scaled, y_train, X_test_scaled, y_test))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nKarşılaştırma Sonuçları:\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\nHangi özellikler önemli? (Feature Importance)\")\n",
    "try:\n",
    "\n",
    "    num_names = numeric_features.tolist()\n",
    "\n",
    "    try:\n",
    "        cat_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features).tolist()\n",
    "    except:\n",
    "        cat_names = [f\"Cat_{i}\" for i in range(X_train_scaled.shape[1] - len(num_names))]\n",
    "\n",
    "    all_features = num_names + cat_names\n",
    "\n",
    "    if len(all_features) != X_train_scaled.shape[1]:\n",
    "        print(\"Uyarı: Özellik isimleri ile veri boyutu uyuşmuyor, grafik çizilmeyecek.\")\n",
    "    else:\n",
    "        feature_importances = rf.feature_importances_\n",
    "        indices = np.argsort(feature_importances)[::-1][:10]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"En Önemli 10 Özellik (Random Forest)\")\n",
    "        plt.bar(range(10), feature_importances[indices], align=\"center\")\n",
    "        plt.xticks(range(10), [all_features[i] for i in indices], rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('regression_feature_importance.png')\n",
    "        print(\"Özellik önem grafiği kaydedildi.\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature importance grafiği çizilirken hata: {e}\")\n",
    "\n",
    "print(\"\\nRegresyon işlemi bitti.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Task\n",
    "Kodlar aşağıdadır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import time\n",
    "\n",
    "print(\"Veri Seti Yükleniyor (Most Streamed Spotify Songs 2024)...\")\n",
    "try:\n",
    "\n",
    "    df = pd.read_csv('Most Streamed Spotify Songs 2024.csv', encoding='latin1')\n",
    "    print(f\"Veri Boyutu: {df.shape}\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: 'Most Streamed Spotify Songs 2024.csv' dosyası bulunamadı!\")\n",
    "    exit()\n",
    "\n",
    "drop_cols = ['Track', 'Album Name', 'Artist', 'ISRC', 'All Time Rank', 'Release Date']\n",
    "\n",
    "cols_to_drop = [c for c in drop_cols if c in df.columns]\n",
    "X = df.drop(columns=cols_to_drop)\n",
    "\n",
    "for col in X.columns:\n",
    "\n",
    "    X[col] = pd.to_numeric(X[col].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "X = X.dropna(axis=1, how='all')\n",
    "\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"Özellik sayısı: {X.shape[1]}\")\n",
    "print(f\"Özellikler: {X.columns.tolist()}\")\n",
    "\n",
    "if not np.isfinite(X).all().all():\n",
    "    print(\"Sonsuz değerler temizleniyor...\")\n",
    "    X = X.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(f\"Özellik sayısı: {X.shape[1]}\")\n",
    "print(f\"Özellikler: {X.columns.tolist()}\")\n",
    "\n",
    "if len(X) > 10000:\n",
    "    print(\"Veri çok büyük olduğu için ilk 5000 satırı alıyorum.\")\n",
    "    X = X.iloc[:5000]\n",
    "\n",
    "print(\"\\nÖlçekleme...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_clustering(name, model_labels, X_data, time_taken):\n",
    "\n",
    "    if len(np.unique(model_labels)) < 2:\n",
    "        print(f\"{name}: Yetersiz küme sayısı (tümü gürültü veya tek küme).\")\n",
    "        return None\n",
    "\n",
    "    sil = silhouette_score(X_data, model_labels, sample_size=1000, random_state=42)\n",
    "    db = davies_bouldin_score(X_data, model_labels)\n",
    "\n",
    "    n_clusters = len(set(model_labels)) - (1 if -1 in model_labels else 0)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Küme Sayısı: {n_clusters}\")\n",
    "    print(f\"Silhouette: {sil:.4f}, Davies-Bouldin: {db:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:,1], hue=model_labels, palette='viridis', legend='full', alpha=0.6)\n",
    "    plt.title(f'{name} Sonuçları (PCA İndirgeme)')\n",
    "    plt.savefig(f'clustering_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return {'Model': name, 'Clusters': n_clusters, 'Silhouette': sil, 'DB Index': db, 'Time': time_taken}\n",
    "\n",
    "print(\"En iyi küme sayısını (K) bulmaya çalıştırılıyor.....\")\n",
    "best_k = 3\n",
    "best_score = -1\n",
    "scores = []\n",
    "\n",
    "for k in range(2, 7):\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    labels_temp = kmeans_temp.fit_predict(X_scaled)\n",
    "\n",
    "    score = silhouette_score(X_scaled, labels_temp, sample_size=1000, random_state=42)\n",
    "    scores.append((k, score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "\n",
    "print(f\"En iyi K değeri: {best_k} (Skor: {best_score:.4f})\")\n",
    "\n",
    "start = time.time()\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "results.append(evaluate_clustering(f\"K-Means (K={best_k})\", kmeans_labels, X_scaled, time.time()-start))\n",
    "\n",
    "print(\"MiniBatch K-Means çalıştırılıyor...\")\n",
    "start = time.time()\n",
    "mb_kmeans = MiniBatchKMeans(n_clusters=4, random_state=42, batch_size=256)\n",
    "mb_labels = mb_kmeans.fit_predict(X_scaled)\n",
    "results.append(evaluate_clustering(\"MiniBatch KMeans\", mb_labels, X_scaled, time.time()-start))\n",
    "\n",
    "print(\"DBSCAN çalıştırılıyor... (Parametre ayarı kritik)\")\n",
    "start = time.time()\n",
    "\n",
    "dbscan = DBSCAN(eps=2.0, min_samples=10)\n",
    "db_labels = dbscan.fit_predict(X_scaled)\n",
    "res = evaluate_clustering(\"DBSCAN\", db_labels, X_scaled, time.time()-start)\n",
    "if res: results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSonuçların karşılaştırılması:\")\n",
    "print(results_df)\n",
    "\n",
    "try:\n",
    "    cols = X.columns.tolist()\n",
    "\n",
    "    x_col = 'Spotify Streams' if 'Spotify Streams' in cols else cols[0]\n",
    "    y_col = 'TikTok Views' if 'TikTok Views' in cols else (cols[1] if len(cols) > 1 else cols[0])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    sns.scatterplot(x=X[x_col], y=X[y_col], hue=kmeans_labels, palette='viridis', alpha=0.6)\n",
    "    plt.title(f'{x_col} vs {y_col} (K-Means Kümeleri)')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig('clustering_scatter_streams.png')\n",
    "    print(f\"Grafik kaydedildi.\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Ek grafik çizilirken hata: {e}\")\n",
    "\n",
    "print(\"\\nKümeleme işlemi bitti.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}