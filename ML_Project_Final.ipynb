{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Colab Environment Setup\n",
    "# @markdown Run this cell to download the datasets from GitHub automatically.\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# GitHub Repo Base URL (Raw content)\n",
    "repo_url = \"https://raw.githubusercontent.com/frzerxz/spotify-ml-analysis/main/\"\n",
    "files = [\"dataset.csv\", \"spotify_data clean.csv\", \"Most Streamed Spotify Songs 2024.csv\"]\n",
    "\n",
    "print(\"Downloading datasets (Force Refresh)...\")\n",
    "timestamp = str(int(time.time()))\n",
    "for file in files:\n",
    "    # Always remove old file to ensure fresh download\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "    \n",
    "    # Add timestamp to bypass cache\n",
    "    url = repo_url + file.replace(\" \", \"%20\") + f\"?v={timestamp}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(file, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"\u2705 Downloaded: {file}\")\n",
    "        else:\n",
    "            print(f\"\u274c Failed to download {file} (Status: {response.status_code})\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error downloading {file}: {e}\")\n",
    "\n",
    "print(\"\\nInstalling necessary libraries...\")\n",
    "!pip install xgboost shap imbalanced-learn\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine \u00d6\u011frenmesi D\u00f6nem \u00d6devi Projesi Raporu (F2025)\n",
    "\n",
    "**\u00d6\u011frenci Ad\u0131 Soyad\u0131:** Firuze Ero\u011flu  \n",
    "**\u00d6\u011frenci No:** 201613709044  \n",
    "**Teslim Tarihi:** 14.12.2025  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Veri Seti Tan\u0131t\u0131m\u0131\n",
    "\n",
    "Bu projede \u00fc\u00e7 farkl\u0131 makine \u00f6\u011frenmesi problemi i\u00e7in, m\u00fczik end\u00fcstrisinin en b\u00fcy\u00fck platformu Spotify'dan elde edilen ger\u00e7ek d\u00fcnya verileri kullan\u0131lm\u0131\u015ft\u0131r. Veri setleri Kaggle platformundan \"Open Access\" (A\u00e7\u0131k Eri\u015fim) lisans\u0131yla temin edilmi\u015ftir. A\u015fa\u011f\u0131da her bir veri setinin kayna\u011f\u0131, i\u00e7eri\u011fi ve proje kapsam\u0131ndaki kullan\u0131m amac\u0131 detayland\u0131r\u0131lm\u0131\u015ft\u0131r.\n",
    "\n",
    "### 1.1. S\u0131n\u0131fland\u0131rma Veri Seti: Spotify Tracks Dataset\n",
    "*   **Veri Kayna\u011f\u0131 Linki:** [Kaggle - Spotify Tracks Dataset](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)\n",
    "*   **Veri Seti Tan\u0131m\u0131:** Bu veri seti, Spotify \u00fczerindeki 125 farkl\u0131 m\u00fczik t\u00fcr\u00fcnden yakla\u015f\u0131k 114.000 \u015fark\u0131y\u0131 kapsamaktad\u0131r. Her bir sat\u0131r bir \u015fark\u0131y\u0131 temsil eder ve \u015fark\u0131ya ait teknik ses \u00f6zelliklerini (audio features) i\u00e7erir.\n",
    "*   **Problem ve Tahmin Hedefi:**\n",
    "    *   **Problem:** M\u00fczik end\u00fcstrisinde bir \u015fark\u0131n\u0131n \"Hit\" olup olmayaca\u011f\u0131n\u0131, \u015fark\u0131 hen\u00fcz piyasaya \u00e7\u0131kmadan sadece ses analizine dayanarak \u00f6ng\u00f6rmek b\u00fcy\u00fck bir ticari de\u011fer ta\u015f\u0131r.\n",
    "    *   **Hedef:** \u015eark\u0131n\u0131n `danceability` (dans edilebilirlik), `energy` (enerji), `loudness` (ses \u015fiddeti), `acousticness` gibi teknik ses \u00f6zniteliklerini kullanarak, \u015fark\u0131n\u0131n **\"Pop\u00fcler\"** (Popularity > 50) olup olmad\u0131\u011f\u0131n\u0131 s\u0131n\u0131fland\u0131rmaya \u00e7al\u0131\u015f\u0131yoruz. Bu, **Binary Classification** (\u0130kili S\u0131n\u0131fland\u0131rma) problemidir.\n",
    "*   **Kullan\u0131lan \u00d6znitelikler (Features):**\n",
    "    *   `danceability`: Tempo, ritim kararl\u0131l\u0131\u011f\u0131 ve vuru\u015f g\u00fcc\u00fcne g\u00f6re \u015fark\u0131n\u0131n dansa uygunlu\u011fu (0.0 - 1.0).\n",
    "    *   `energy`: \u015eark\u0131n\u0131n yo\u011funluk ve aktivite \u00f6l\u00e7\u00fcm\u00fc. H\u0131zl\u0131, g\u00fcr\u00fclt\u00fcl\u00fc \u015fark\u0131lar 1.0'a yak\u0131nd\u0131r.\n",
    "    *   `valence`: \u015eark\u0131n\u0131n ta\u015f\u0131d\u0131\u011f\u0131 m\u00fczikal pozitiflik (mutluluk/h\u00fcz\u00fcn) d\u00fczeyi.\n",
    "    *   `instrumentalness`: \u015eark\u0131n\u0131n ne kadar enstr\u00fcmantal oldu\u011fu (vokal olup olmad\u0131\u011f\u0131).\n",
    "    *   `duration_ms`: \u015eark\u0131n\u0131n milisaniye cinsinden s\u00fcresi.\n",
    "\n",
    "### 1.2. Regresyon Veri Seti: Spotify Global Music Dataset\n",
    "*   **Veri Kayna\u011f\u0131 Linki:** [Kaggle - Spotify Global Music Dataset 2009-2025](https://www.kaggle.com/datasets/wardabilal/spotify-global-music-dataset-20092025?select=spotify_data+clean.csv) (Kullan\u0131lan dosya: `spotify_data clean.csv`)\n",
    "*   **Veri Seti Tan\u0131m\u0131:** 2009-2025 y\u0131llar\u0131 aras\u0131ndaki k\u00fcresel m\u00fczik trendlerini i\u00e7eren, temizlenmi\u015f ve yap\u0131land\u0131r\u0131lm\u0131\u015f bir veri setidir. Yakla\u015f\u0131k 8.500 \u00f6rnek i\u00e7ermektedir.\n",
    "*   **Problem ve Tahmin Hedefi:**\n",
    "    *   **Problem:** Bir \u015fark\u0131n\u0131n ba\u015far\u0131s\u0131 sadece ses \u00f6zelliklerine mi ba\u011fl\u0131d\u0131r, yoksa sanat\u00e7\u0131n\u0131n \u015f\u00f6hreti ve alb\u00fcm\u00fcn yap\u0131s\u0131 daha m\u0131 etkilidir?\n",
    "    *   **Hedef:** \u015eark\u0131n\u0131n ve sanat\u00e7\u0131n\u0131n metadatalar\u0131n\u0131 (metadata) kullanarak, \u015fark\u0131n\u0131n Spotify \u00fczerindeki **Pop\u00fclerlik Puan\u0131n\u0131 (0 ile 100 aras\u0131nda s\u00fcrekli bir de\u011fer)** say\u0131sal olarak tahmin etmek. Bu, bir **Regresyon** (Kestirim) problemidir.\n",
    "*   **Kullan\u0131lan \u00d6znitelikler (Features):**\n",
    "    *   `artist_popularity`: \u015eark\u0131y\u0131 s\u00f6yleyen sanat\u00e7\u0131n\u0131n genel pop\u00fclerlik skoru.\n",
    "    *   `artist_followers`: Sanat\u00e7\u0131n\u0131n takip\u00e7i say\u0131s\u0131 (Sanat\u00e7\u0131n\u0131n hayran kitlesi).\n",
    "    *   `album_total_tracks`: \u015eark\u0131n\u0131n bulundu\u011fu alb\u00fcmdeki toplam \u015fark\u0131 say\u0131s\u0131.\n",
    "    *   `album_type`: Alb\u00fcm\u00fcn t\u00fcr\u00fc (Single, Album, Compilation).\n",
    "    *   `explicit`: \u015eark\u0131n\u0131n sans\u00fcrl\u00fc/k\u00fcf\u00fcrl\u00fc i\u00e7erik bar\u0131nd\u0131r\u0131p bar\u0131nd\u0131rmad\u0131\u011f\u0131.\n",
    "\n",
    "### 1.3. K\u00fcmeleme Veri Seti: Most Streamed Spotify Songs 2024\n",
    "*   **Veri Kayna\u011f\u0131 Linki:** [Kaggle - Most Streamed Spotify Songs 2024](https://www.kaggle.com/datasets/nelgiriyewithana/most-streamed-spotify-songs-2024)\n",
    "*   **Veri Seti Tan\u0131m\u0131:** 2024 y\u0131l\u0131n\u0131n en \u00e7ok dinlenen \u015fark\u0131lar\u0131n\u0131 ve bu \u015fark\u0131lar\u0131n farkl\u0131 platformlardaki (Spotify, TikTok, YouTube, vb.) etkile\u015fim say\u0131lar\u0131n\u0131 i\u00e7eren g\u00fcncel bir veri setidir.\n",
    "*   **Problem ve Analiz Hedefi:**\n",
    "    *   **Problem:** Milyonlarca dinlenen \u015fark\u0131lar aras\u0131nda gizli \u00f6r\u00fcnt\u00fcler veya farkl\u0131 ba\u015far\u0131 profilleri var m\u0131d\u0131r? (\u00d6rne\u011fin: \"TikTok sayesinde \u00fcnl\u00fc olanlar\" vs \"Organik hitler\").\n",
    "    *   **Hedef:** Veri setindeki \u015fark\u0131lar\u0131n **Etiketsiz** (Unsupervised) olarak benzerliklerine g\u00f6re grupland\u0131r\u0131lmas\u0131d\u0131r. \u015eark\u0131lar\u0131 dinlenme say\u0131lar\u0131, \u00e7alma listelerine eklenme s\u0131kl\u0131\u011f\u0131 ve sosyal medya etkile\u015fimlerine g\u00f6re **Segmentlere (K\u00fcmeler)** ay\u0131rarak, m\u00fczik d\u00fcnyas\u0131ndaki farkl\u0131 ba\u015far\u0131 tiplerini analiz etmeyi hedefliyoruz.\n",
    "*   **Kullan\u0131lan \u00d6znitelikler (Features):**\n",
    "    *   `Spotify Streams`: Toplam dinlenme say\u0131s\u0131.\n",
    "    *   `Spotify Playlist Count`: \u015eark\u0131n\u0131n ka\u00e7 farkl\u0131 \u00e7alma listesine eklendi\u011fi.\n",
    "    *   `TikTok Views`: \u015eark\u0131n\u0131n TikTok platformundaki g\u00f6r\u00fcnt\u00fclenme say\u0131s\u0131.\n",
    "    *   `YouTube Views`: \u015eark\u0131n\u0131n YouTube g\u00f6r\u00fcnt\u00fclenme say\u0131s\u0131.\n",
    "    *   `AirPlay Spins`: Radyolarda \u00e7al\u0131nma say\u0131s\u0131.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Uygulanan Y\u00f6ntemler ve \u00d6n \u0130\u015fleme\n",
    "\n",
    "### 2.1. Veri \u00d6n \u0130\u015fleme (Preprocessing)\n",
    "T\u00fcm veri setleri i\u00e7in a\u015fa\u011f\u0131daki standart ad\u0131mlar uygulanm\u0131\u015ft\u0131r:\n",
    "*   **Eksik Veriler (Missing Values):** Say\u0131sal s\u00fctunlardaki eksik veriler medyan ile, kategorik veriler sabit de\u011fer veya en s\u0131k g\u00f6r\u00fclen de\u011fer ile dolduruldu ('SimpleImputer').\n",
    "*   **\u00d6zellik \u00d6l\u00e7ekleme (Scaling):** T\u00fcm algoritmalar\u0131n (\u00f6zellikle K-Means ve Logistic Regression) performans\u0131n\u0131 art\u0131rmak i\u00e7in `StandardScaler` ile veriler \u00f6l\u00e7eklendi (Ortalama=0, Varyans=1).\n",
    "*   **Kategorik D\u00f6n\u00fc\u015f\u00fcm:** `OneHotEncoder` kullan\u0131larak 'album_type' ve 'explicit' gibi kategorik veriler say\u0131sal matrise d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc.\n",
    "*   **Dengesiz Veri \u00c7\u00f6z\u00fcm\u00fc (Undersampling):** S\u0131n\u0131fland\u0131rma g\u00f6revinde, \"Pop\u00fcler Olmayan\" \u015fark\u0131lar\u0131n say\u0131s\u0131 \"Pop\u00fcler\" olanlardan \u00e7ok daha fazlayd\u0131. Modelin \u00e7o\u011funluk s\u0131n\u0131f\u0131na meyletmesini \u00f6nlemek i\u00e7in **RandomUnderSampler** kullan\u0131larak \u00e7o\u011funluk s\u0131n\u0131f\u0131ndaki veri say\u0131s\u0131 azalt\u0131ld\u0131 ve iki s\u0131n\u0131f e\u015fitlendi. Bu, \u00f6zellikle 'Recall' de\u011ferini art\u0131rmak i\u00e7in kritik bir ad\u0131md\u0131.\n",
    "*   **Ayk\u0131r\u0131 De\u011fer Analizi (Outlier Handling):** Regresyon g\u00f6revinde IQR (Interquartile Range) y\u00f6ntemi kullan\u0131larak veri setindeki a\u015f\u0131r\u0131 u\u00e7 de\u011ferler temizlendi.\n",
    "*   **Veri Ayr\u0131m\u0131 ve Do\u011frulama (Validation):** T\u00fcm g\u00f6revlerde veri seti `%80 E\u011fitim - %20 Test` oran\u0131nda ve `stratify` (s\u0131n\u0131f dengesini koruyarak) parametresiyle ayr\u0131ld\u0131. Ayr\u0131ca, **Random Forest** modeli e\u011fitilirken **3-Katl\u0131 \u00c7apraz Do\u011frulama (3-Fold Cross-Validation)** (\"k-fold cross val\") kullan\u0131ld\u0131. Bu y\u00f6ntem, modelin veriye a\u015f\u0131r\u0131 uyum (overfitting) sa\u011flamas\u0131n\u0131 engelledi ve sonu\u00e7lar\u0131n g\u00fcvenilirli\u011fini art\u0131rd\u0131.\n",
    "\n",
    "### 2.2. Algoritma Se\u00e7imi\n",
    "*   **S\u0131n\u0131fland\u0131rma:** Logistic Regression, Random Forest Classifier, XGBoost. (RF i\u00e7in `RandomizedSearchCV` ile optimizasyon yap\u0131ld\u0131).\n",
    "*   **Regresyon:** Linear Regression, Random Forest Regressor, Gradient Boosting.\n",
    "*   **K\u00fcmeleme:** K-Means, MiniBatch K-Means, DBSCAN. (K de\u011feri Silhouette analizi ile belirlendi).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Sonu\u00e7lar ve Metrikler\n",
    "\n",
    "### 3.1. S\u0131n\u0131fland\u0131rma Sonu\u00e7lar\u0131 ve G\u00f6rseller\n",
    "S\u0131n\u0131fland\u0131rma g\u00f6revinde \"Pop\u00fclerlik\" tahmini i\u00e7in modellerin performans\u0131 kar\u015f\u0131la\u015ft\u0131r\u0131lm\u0131\u015ft\u0131r.\n",
    "\n",
    "#### **A. Model Performans\u0131 ve Kar\u015f\u0131la\u015ft\u0131rma**\n",
    "A\u015fa\u011f\u0131daki grafik, \u00fc\u00e7 modelin \"Accuracy\" (Do\u011fruluk) ve \"Recall\" (Yakama) oranlar\u0131n\u0131 g\u00f6stermektedir.\n",
    "![Model Kar\u015f\u0131la\u015ft\u0131rmas\u0131](model_comparison_chart.png)\n",
    "\n",
    "*   **Yorum:** Grafikte g\u00f6r\u00fcld\u00fc\u011f\u00fc \u00fczere, **Random Forest (Optimized)** modeli en dengeli performans\u0131 sergilemi\u015ftir. Hiperparametre optimizasyonu \u00f6ncesi \"Pop\u00fcler\" s\u0131n\u0131f\u0131n\u0131 yakalamakta zorlanan model, optimizasyon ve undersampling sonras\u0131 her iki s\u0131n\u0131f\u0131 da %75 civar\u0131nda ba\u015far\u0131yla tahmin edebilmi\u015ftir.\n",
    "\n",
    "#### **B. Hata Matrisi (Confusion Matrix)**\n",
    "Modelin nerede hata yapt\u0131\u011f\u0131n\u0131 anlamak i\u00e7in Random Forest modelinin Karma\u015f\u0131kl\u0131k Matrisi (Confusion Matrix) a\u015fa\u011f\u0131dad\u0131r:\n",
    "![Confusion Matrix](cm_Random_Forest_(Optimized).png)\n",
    "\n",
    "*   **Yorum:** Matris incelendi\u011finde, modelin \"Pop\u00fcler Olmayan\" (0) \u015fark\u0131lar\u0131n b\u00fcy\u00fck \u00e7o\u011funlu\u011funu do\u011fru bildi\u011fi, ancak \"Pop\u00fcler\" (1) \u015fark\u0131lar\u0131n bir k\u0131sm\u0131n\u0131 hala ka\u00e7\u0131rd\u0131\u011f\u0131 g\u00f6r\u00fclmektedir. M\u00fczik ba\u015far\u0131s\u0131n\u0131n sadece ses \u00f6zelliklerine ba\u011fl\u0131 olmamas\u0131 (pazarlama, b\u00fct\u00e7e vb.) bu hatan\u0131n do\u011fal sebebidir.\n",
    "\n",
    "#### **C. Model A\u00e7\u0131klanabilirli\u011fi (SHAP Analizi)**\n",
    "Modelin *neden* bu karar\u0131 verdi\u011fini anlamak i\u00e7in XGBoost modeli \u00fczerinde SHAP analizi yap\u0131lm\u0131\u015ft\u0131r:\n",
    "![SHAP Analizi](shap_summary.png)\n",
    "\n",
    "*   **Detayl\u0131 Analiz:**\n",
    "    1.  **Loudness (Ses \u015eiddeti):** En belirleyici \u00f6zellik. Grafikte sa\u011fa do\u011fru (y\u00fcksek de\u011ferler) k\u0131rm\u0131z\u0131 noktalar\u0131n yo\u011funla\u015fmas\u0131, **daha g\u00fcr\u00fclt\u00fcl\u00fc/y\u00fcksek sesli \u015fark\u0131lar\u0131n pop\u00fcler olma ihtimalinin daha y\u00fcksek oldu\u011funu** g\u00f6stermektedir.\n",
    "    2.  **Acousticness:** D\u00fc\u015f\u00fck akustik (daha elektronik/\u00fcretilmi\u015f) \u015fark\u0131lar pop\u00fclerlikle pozitif korelasyon g\u00f6stermektedir.\n",
    "    3.  **Duration:** \u00c7ok uzun \u015fark\u0131lar pop\u00fclerlik \u015fans\u0131n\u0131 d\u00fc\u015f\u00fcrmektedir.\n",
    "\n",
    "### 3.2. Regresyon Sonu\u00e7lar\u0131 ve G\u00f6rseller\n",
    "\u015eark\u0131 pop\u00fclaritesini (0-100) tahmin etme ba\u015far\u0131s\u0131:\n",
    "\n",
    "#### **A. Tahmin Ba\u015far\u0131s\u0131 (Ger\u00e7ek vs Tahmin)**\n",
    "Random Forest modelinin tahminleri ile ger\u00e7ek de\u011ferlerin kar\u015f\u0131la\u015ft\u0131rmas\u0131:\n",
    "![Regresyon Tahminleri](reg_pred_Random_Forest.png)\n",
    "\n",
    "*   **Yorum:** \u0130deal durumda t\u00fcm noktalar\u0131n k\u0131rm\u0131z\u0131 k\u00f6\u015fegen \u00e7izgi \u00fczerinde olmas\u0131 gerekirdi. Grafikteki sa\u00e7\u0131l\u0131m, modelin genel trendi yakalad\u0131\u011f\u0131n\u0131 (R\u00b2 ~ 0.24) ancak birebir puan tahmininde sapmalar ya\u015fad\u0131\u011f\u0131n\u0131 g\u00f6sterir. RMSE (Hata Kareler Ortalamas\u0131) yakla\u015f\u0131k 20 puand\u0131r; yani model bir \u015fark\u0131ya \"60 puan\" dedi\u011finde, ger\u00e7ek puan 40 veya 80 olabilir.\n",
    "\n",
    "#### **B. \u00d6zellik \u00d6nemi (Feature Importance - Feature Selection)**\n",
    "Hangi fakt\u00f6rler bir \u015fark\u0131n\u0131n puan\u0131n\u0131 art\u0131r\u0131r?\n",
    "![Feature Importance](regression_feature_importance.png)\n",
    "\n",
    "*   **Kritik Bulgular:**\n",
    "    *   **Artist Popularity (Sanat\u00e7\u0131 Pop\u00fclerli\u011fi):** Grafikteki en uzun \u00e7ubuktur. Bu, \u015fark\u0131n\u0131n *nas\u0131l* duyuldu\u011fundan ziyade *kimin* s\u00f6yledi\u011finin ba\u015far\u0131da en b\u00fcy\u00fck etken oldu\u011funu kan\u0131tlar.\n",
    "    *   **Artist Followers:** \u0130kinci s\u0131rada sanat\u00e7\u0131n\u0131n hayran kitlesi gelmektedir.\n",
    "    *   **Explicit (Sans\u00fcr):** \u015eark\u0131n\u0131n k\u00fcf\u00fcrl\u00fc olup olmamas\u0131n\u0131n pop\u00fclerlik \u00fczerinde marjinal bir etkisi vard\u0131r.\n",
    "\n",
    "### 3.3. K\u00fcmeleme Sonu\u00e7lar\u0131 ve G\u00f6rseller (PCA ve Segmentasyon)\n",
    "\u015eark\u0131lar\u0131n dinlenme ve etkile\u015fim say\u0131lar\u0131na g\u00f6re grupland\u0131r\u0131lmas\u0131:\n",
    "\n",
    "#### **A. K\u00fcme Da\u011f\u0131l\u0131m\u0131 (K-Means, K=2) ve PCA**\n",
    "Veri seti PCA (Principal Component Analysis) ile 2 boyuta indirgenmi\u015f ve k\u00fcmeler g\u00f6rselle\u015ftirilmi\u015ftir:\n",
    "![K-Means K\u00fcmeleme](clustering_K-Means_(K=2).png)\n",
    "\n",
    "*   **K\u00fcme Analizi:**\n",
    "    *   **K\u00fcme 0 (Mor):** D\u00fc\u015f\u00fck ve orta seviye dinlenmeye sahip \u015fark\u0131lar\u0131n olu\u015fturdu\u011fu ana g\u00f6vde. \u015eark\u0131lar\u0131n %90'\u0131 buradad\u0131r.\n",
    "    *   **K\u00fcme 1 (Sar\u0131):** \"S\u00fcper Hit\" \u015fark\u0131lar. Say\u0131lar\u0131 azd\u0131r ancak grafikte di\u011ferlerinden net bir \u015fekilde ayr\u0131\u015fm\u0131\u015flard\u0131r.\n",
    "\n",
    "#### **B. Platform Etkile\u015fimi (Spotify vs TikTok)**\n",
    "\u015eark\u0131lar\u0131n Spotify dinlenmeleri ile TikTok g\u00f6r\u00fcnt\u00fclenmeleri aras\u0131ndaki ili\u015fki:\n",
    "![Scatter Plot](clustering_scatter_streams.png)\n",
    "\n",
    "*   **Yorum:** Grafikte, TikTok'ta \u00e7ok g\u00f6r\u00fcnt\u00fclenen \u015fark\u0131lar\u0131n (Y ekseni y\u00fcksek), Spotify'da da \u00e7ok dinlendi\u011fi (X ekseni y\u00fcksek) bariz bir **pozitif korelasyon** g\u00f6r\u00fclmektedir. Bu, sosyal medya viralitesinin m\u00fczik ba\u015far\u0131s\u0131ndaki kilit rol\u00fcn\u00fc do\u011frular.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Sonu\u00e7lar\u0131n \u00d6zeti (Summary of Results)\n",
    "\n",
    "Kodlar\u0131n son \u00e7al\u0131\u015ft\u0131r\u0131lmas\u0131 neticesinde elde edilen ba\u015far\u0131 metrikleri ve s\u00fcreler a\u015fa\u011f\u0131daki tabloda \u00f6zetlenmi\u015ftir:\n",
    "\n",
    "| G\u00f6rev | Model | Ana Metrik | De\u011fer | E\u011fitim S\u00fcresi (sn) |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **S\u0131n\u0131fland\u0131rma** | Logistic Regression | Accuracy | %56 | 0.04 sn |\n",
    "| | Random Forest (Opt) | Accuracy | %74 | 100.06 sn |\n",
    "| | XGBoost | Accuracy | %74 | 2.63 sn |\n",
    "| **Regresyon** | Linear Regression | R2 Score | 0.22 | 0.002 sn |\n",
    "| | Random Forest | R2 Score | 0.24 | 0.71 sn |\n",
    "| | Gradient Boosting | R2 Score | 0.24 | 0.50 sn |\n",
    "| **K\u00fcmeleme** | K-Means (K=2) | Silhouette | 0.45 | 0.003 sn |\n",
    "| | DBSCAN | Silhouette | 0.09 | 0.06 sn |\n",
    "\n",
    "*(Not: Tablodaki de\u011ferler \u00e7al\u0131\u015f\u0131lan bilgisayar\u0131n donan\u0131m\u0131na g\u00f6re k\u00fc\u00e7\u00fck de\u011fi\u015fiklikler g\u00f6sterebilir.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Tart\u0131\u015fma ve Yorumlar (Discussion)\n",
    "\n",
    "Proje sonu\u00e7lar\u0131nda elde edilen teknik bulgular\u0131n yorumlanmas\u0131:\n",
    "\n",
    "1.  **Dengesiz Veri Y\u00f6netimi:** S\u0131n\u0131fland\u0131rma g\u00f6revinde, veri seti dengesiz oldu\u011fu i\u00e7in ba\u015flang\u0131\u00e7ta model sadece \u00e7o\u011funluk s\u0131n\u0131f\u0131n\u0131 (Pop\u00fcler Olmayan) tahmin ediyordu. `Undersampling` tekni\u011fi uyguland\u0131ktan sonra do\u011fruluk (accuracy) d\u00fc\u015fm\u00fc\u015f gibi g\u00f6r\u00fcnse de, asl\u0131nda *Recall* (Duyarl\u0131l\u0131k) metri\u011fi ciddi oranda artarak modelin \"Pop\u00fcler\" \u015fark\u0131lar\u0131 yakalama yetene\u011fi kazand\u0131r\u0131ld\u0131. Bu, ger\u00e7ek hayatta \"Hit \u015eark\u0131\" avc\u0131l\u0131\u011f\u0131 i\u00e7in daha do\u011fru bir yakla\u015f\u0131md\u0131r.\n",
    "2.  **\u00d6zniteliklerin G\u00fcc\u00fc (Feature Relevance):** Regresyon analizi net bir \u015fekilde g\u00f6sterdi ki, bir \u015fark\u0131n\u0131n pop\u00fclerli\u011fi, o \u015fark\u0131n\u0131n m\u00fczikal yap\u0131s\u0131ndan (bpm, key, mode) ziyade, sanat\u00e7\u0131n\u0131n mevcut \u015f\u00f6hreti (`artist_popularity`) ile ili\u015fkilidir. Bu durum, m\u00fczik end\u00fcstrisinde \"y\u0131ld\u0131z g\u00fcc\u00fcn\u00fcn\" i\u00e7erikten daha bask\u0131n olabilece\u011fi tezini destekler.\n",
    "3.  **K\u00fcmeleme Yap\u0131s\u0131:** M\u00fczik piyasas\u0131 homojen bir da\u011f\u0131l\u0131m g\u00f6stermez. K-Means ve Silhouette analizi, verinin en iyi 2 k\u00fcmeye ayr\u0131ld\u0131\u011f\u0131n\u0131 g\u00f6sterdi: \"Mega Hit'ler\" ve \"Di\u011ferleri\". Bu, end\u00fcstrideki gelir da\u011f\u0131l\u0131m\u0131 e\u015fitsizli\u011fine (Pareto Prensibi) i\u015faret eder.\n",
    "4.  **Cross-Validation Etkisi:** Model e\u011fitiminde sadece `Train-Test Split` yerine `Cross-Validation` kullan\u0131lmas\u0131, \u00f6zellikle k\u00fc\u00e7\u00fck veri setlerinde (Regresyon verimiz 8.500 sat\u0131rd\u0131) modelin kararl\u0131l\u0131\u011f\u0131n\u0131 art\u0131rd\u0131. Tek bir test setine ba\u011fl\u0131 kalmak yerine verinin farkl\u0131 par\u00e7alar\u0131nda test yap\u0131lmas\u0131, elde etti\u011fimiz R\u00b2 skorunun \u015fans eseri olmad\u0131\u011f\u0131n\u0131 do\u011frulad\u0131.\n",
    "5.  **Model Performanslar\u0131:** A\u011fa\u00e7 tabanl\u0131 modellerin (Random Forest ve XGBoost), do\u011frusal modellere (Linear/Logistic Regression) g\u00f6re karma\u015f\u0131k ili\u015fkileri modellemede daha ba\u015far\u0131l\u0131 oldu\u011fu g\u00f6zlemlendi. Ancak bu modellerin e\u011fitimi ve hiperparametre optimizasyonu (GridSearchCV) \u00e7ok daha uzun s\u00fcrd\u00fc (~100 sn vs ~0.1 sn).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Kazan\u0131mlar / \u00d6\u011frenilenler (Learnings)\n",
    "\n",
    "Bu d\u00f6nem \u00f6devi projesi kapsam\u0131nda \u015funlar \u00f6\u011frenilmi\u015ftir:\n",
    "*   **Veri Kalitesinin \u00d6nemi:** Ger\u00e7ek d\u00fcnya verilerinin \"temiz\" olmad\u0131\u011f\u0131n\u0131, eksik verilerin (missing values) ve g\u00fcr\u00fclt\u00fcn\u00fcn (noise) model ba\u015far\u0131s\u0131n\u0131 do\u011frudan etkiledi\u011fi g\u00f6r\u00fcld\u00fc.\n",
    "*   **Metriklerin Do\u011fru Okunmas\u0131:** Sadece `Accuracy`'ye bakman\u0131n yan\u0131lt\u0131c\u0131 olabilece\u011fi, dengesiz veri setlerinde `Recall` ve `F1-Score`'un hayati oldu\u011fu anla\u015f\u0131ld\u0131.\n",
    "*   **\u0130\u015f Bilgisi (Domain Knowledge):** Veri biliminde sadece kod yazman\u0131n yetmedi\u011fi, verinin ait oldu\u011fu alan\u0131n (m\u00fczik end\u00fcstrisi) dinamiklerini bilmenin (\u00f6rn: TikTok'un etkisi) analiz ba\u015far\u0131s\u0131n\u0131 art\u0131rd\u0131\u011f\u0131 fark edildi.\n",
    "*   **AI ve Otomasyon:** Hiperparametre optimizasyonu ve \u00f6zellik se\u00e7imi gibi s\u00fcre\u00e7lerin yapay zeka ve otomasyon ara\u00e7lar\u0131yla ne kadar h\u0131zland\u0131r\u0131labilece\u011fi deneyimlendi.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Akademik D\u00fcr\u00fcstl\u00fck ve Yapay Zek\u00e2 Kullan\u0131m\u0131 Beyan\u0131\n",
    "\n",
    "Bu \u00f6devin haz\u0131rlanmas\u0131nda;\n",
    "*   **Kodlama:** Python scriptlerinin (`pandas`, `scikit-learn`, `imblearn` kullan\u0131m\u0131) haz\u0131rlanmas\u0131, hata ay\u0131klama (debugging) ve grafik \u00e7izdirme s\u00fcre\u00e7lerinde **AI Asistan\u0131** (Antigravity/Gemini) deste\u011fi al\u0131nm\u0131\u015ft\u0131r. AI, kodun iskeletini olu\u015fturmada ve syntax hatalar\u0131n\u0131 d\u00fczeltmede kullan\u0131lm\u0131\u015ft\u0131r.\n",
    "*   **Strateji:** Dengesiz veri setlerinde `recall` sorununu \u00e7\u00f6zmek i\u00e7in `undersampling` y\u00f6nteminin se\u00e7ilmesi ve uygulanmas\u0131nda AI rehberli\u011finden faydalan\u0131lm\u0131\u015ft\u0131r. Ancak veri setlerinin se\u00e7imi ve problemin kurgulanmas\u0131 taraf\u0131mca yap\u0131lm\u0131\u015ft\u0131r.\n",
    "*   **Yorumlama:** Elde edilen teknik \u00e7\u0131kt\u0131lar\u0131n (R\u00b2 skoru, SHAP de\u011ferleri, Recall dengesi, Confusion Matrix yorumlar\u0131) analizi ve raporlanmas\u0131, kendi c\u00fcmlelerimle ve derste \u00f6\u011frenilen bilgiler \u0131\u015f\u0131\u011f\u0131nda \u015fahs\u0131m taraf\u0131ndan yap\u0131lm\u0131\u015ft\u0131r.\n",
    "\n",
    "---\n",
    "\n",
    "### Ek 1: \u00c7al\u0131\u015fma Ortam\u0131 (Donan\u0131m \u00d6zellikleri)\n",
    "Proje a\u015fa\u011f\u0131daki donan\u0131m \u00f6zelliklerine sahip bilgisayarda \u00e7al\u0131\u015ft\u0131r\u0131lm\u0131\u015ft\u0131r:\n",
    "*   **Model:** Monster Abra A5 V15.7\n",
    "*   **\u0130\u015fletim Sistemi:** Windows\n",
    "*   **\u0130\u015flemci (CPU):** Intel Core i5 10. Nesil\n",
    "*   **Bellek (RAM):** 16 GB (DDR4)\n",
    "*   **Ekran Kart\u0131 (GPU):** NVIDIA GeForce GTX 1650 Ti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task\n",
    "Kodlar a\u015fa\u011f\u0131dad\u0131r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import time\n",
    "\n",
    "print(\"Veri Seti Y\u00fckleniyor (Spotify Dataset)...\")\n",
    "try:\n",
    "    df = pd.read_csv('dataset.csv', encoding='latin1')\n",
    "    print(f\"Veri seti boyutu: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: 'dataset.csv' bulunamad\u0131.\")\n",
    "    exit()\n",
    "\n",
    "target_col = 'is_popular'\n",
    "df[target_col] = (df['popularity'] > 50).astype(int)\n",
    "print(f\"Yeni hedef de\u011fi\u015fken: {target_col}\")\n",
    "\n",
    "cols_to_drop = ['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'track_genre']\n",
    "feature_cols = [c for c in df.columns if c not in cols_to_drop and c != target_col]\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "print(f\"Kulland\u0131\u011f\u0131m \u00f6zellikler:\\n{X.columns.tolist()}\")\n",
    "\n",
    "if 'explicit' in X.columns:\n",
    "    X['explicit'] = X['explicit'].astype(int)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train boyutu: {X_train.shape}, S\u0131n\u0131f Da\u011f\u0131l\u0131m\u0131: {np.bincount(y_train)}\")\n",
    "\n",
    "try:\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    print(f\"Resampled train boyutu: {X_train_resampled.shape}, S\u0131n\u0131f Da\u011f\u0131l\u0131m\u0131: {np.bincount(y_train_resampled)}\")\n",
    "    X_train = X_train_resampled\n",
    "    y_train = y_train_resampled\n",
    "except ImportError:\n",
    "    print(\"UYARI: 'imblearn' k\u00fct\u00fcphanesi yok. Manuel undersampling uyguluyorum...\")\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    minority_count = y_train.value_counts().min()\n",
    "    df_0 = train_df[train_df[target_col] == 0].sample(minority_count, random_state=42)\n",
    "    df_1 = train_df[train_df[target_col] == 1]\n",
    "    balanced_df = pd.concat([df_0, df_1])\n",
    "    X_train = balanced_df.drop(columns=[target_col])\n",
    "    y_train = balanced_df[target_col]\n",
    "    print(f\"Manuel Resampled Boyut: {X_train.shape}\")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"\\nAyk\u0131r\u0131 de\u011ferleri (Outliers) inceliyorum...\")\n",
    "try:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if 'duration_ms' in df.columns:\n",
    "        sns.boxplot(x=df['duration_ms'] / 60000)\n",
    "        plt.title('\u015eark\u0131 S\u00fcresi Da\u011f\u0131l\u0131m\u0131 (Dakika)')\n",
    "        plt.xlabel('S\u00fcre (dk)')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if 'danceability' in df.columns:\n",
    "        sns.histplot(df['danceability'], bins=30, kde=True)\n",
    "        plt.title('Dans Edilebilirlik Da\u011f\u0131l\u0131m\u0131')\n",
    "    else:\n",
    "        sns.histplot(df.iloc[:, 0], bins=30)\n",
    "        plt.title('Birinci S\u00fctun Da\u011f\u0131l\u0131m\u0131')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('classification_outliers.png')\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Grafik hatas\u0131: {e}\")\n",
    "\n",
    "print(\"\\nModelleri e\u011fitiyorum...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_prob = model.predict_proba(X_te)[:, 1] if hasattr(model, \"predict_proba\") else np.zeros(len(y_te))\n",
    "\n",
    "    acc = accuracy_score(y_te, y_pred)\n",
    "    prec = precision_score(y_te, y_pred, average='weighted')\n",
    "    rec = recall_score(y_te, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_te, y_pred, average='weighted')\n",
    "\n",
    "    report_dict = classification_report(y_te, y_pred, output_dict=True)\n",
    "    recall_0 = report_dict['0']['recall']\n",
    "    recall_1 = report_dict['1']['recall']\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_te, y_prob)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "\n",
    "    print(f\"--- {name} Sonu\u00e7lar\u0131 ---\")\n",
    "    print(f\"B\u00fct\u00fcn: Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "    print(f\"Recall (Pop\u00fcler Olmayan): {recall_0:.4f}\")\n",
    "    print(f\"Recall (Pop\u00fcler): {recall_1:.4f}\")\n",
    "    print(classification_report(y_te, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_te, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('Ger\u00e7ek')\n",
    "    plt.xlabel('Tahmin')\n",
    "    plt.savefig(f'cm_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        'Model': name, 'Accuracy': acc, 'Precision': prec,\n",
    "        'Recall': rec, 'F1': f1, 'AUC': auc,\n",
    "        'Recall_0': recall_0, 'Recall_1': recall_1,\n",
    "        'Time (s)': train_time\n",
    "    }\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "results.append(evaluate_model(\"Logistic Regression\", lr_model, X_train_processed, y_train, X_test_processed, y_test))\n",
    "\n",
    "print(\"\\nRandom Forest i\u00e7in en iyi parametreleri ar\u0131yorum...\")\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_search = time.time()\n",
    "random_search.fit(X_train_processed, y_train)\n",
    "print(f\"Bulunan en iyi parametreler: {random_search.best_params_}\")\n",
    "print(f\"Arama s\u00fcresi: {time.time() - start_search:.2f} sn\")\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "results.append(evaluate_model(\"Random Forest (Optimized)\", best_rf, X_train_processed, y_train, X_test_processed, y_test))\n",
    "\n",
    "print(\"\\nXGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "results.append(evaluate_model(\"XGBoost\", xgb_model, X_train_processed, y_train, X_test_processed, y_test))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nKar\u015f\u0131la\u015ft\u0131rma Tablosu:\")\n",
    "print(results_df)\n",
    "results_df.to_csv('model_comparison_classification.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "results_df.set_index('Model')[['Accuracy', 'Recall_1', 'AUC']].plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performans\u0131 (Accuracy vs Pop\u00fcler \u015eark\u0131 Yakalama)')\n",
    "plt.ylabel('Skor')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_chart.png')\n",
    "\n",
    "print(\"\\nSHAP ile model analizi...\")\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(xgb_model)\n",
    "    X_shap = X_test_processed[:100].toarray() if hasattr(X_test_processed, \"toarray\") else X_test_processed[:100]\n",
    "    shap_values = explainer.shap_values(X_shap)\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_shap, show=False, feature_names=numeric_features.tolist())\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_summary.png')\n",
    "except Exception as e:\n",
    "    print(f\"SHAP hatas\u0131: {e}\")\n",
    "\n",
    "print(\"\\nS\u0131n\u0131fland\u0131rma i\u015flemi bitti.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task\n",
    "Kodlar a\u015fa\u011f\u0131dad\u0131r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "print(\"Veri Seti Y\u00fckleniyor (Spotify Data)...\")\n",
    "try:\n",
    "    df = pd.read_csv('spotify_data clean.csv', encoding='latin1')\n",
    "    print(f\"Veri seti boyutu: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: 'spotify_data clean.csv' bulunamad\u0131.\")\n",
    "    exit()\n",
    "\n",
    "target_col = 'track_popularity'\n",
    "\n",
    "cols_to_drop = ['track_id', 'track_name', 'artist_name', 'album_id', 'album_name', 'album_release_date', 'artist_genres', target_col]\n",
    "\n",
    "X = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"Kulland\u0131\u011f\u0131m \u00f6zellikler:\", X.columns.tolist())\n",
    "\n",
    "print(\"\\nVeri \u00f6n i\u015fleme ad\u0131mlar\u0131...\")\n",
    "\n",
    "print(\"\\nVeri \u00f6n i\u015fleme ad\u0131mlar\u0131...\")\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "Q1 = df[numeric_features].quantile(0.25)\n",
    "Q3 = df[numeric_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "condition = ~((df[numeric_features] < (Q1 - 3 * IQR)) | (df[numeric_features] > (Q3 + 3 * IQR))).any(axis=1)\n",
    "original_len = len(df)\n",
    "df_clean = df[condition]\n",
    "X = df_clean.drop(columns=[c for c in cols_to_drop if c in df_clean.columns])\n",
    "y = df_clean[target_col]\n",
    "\n",
    "print(f\"Outlier temizli\u011finden sonra kalan veri: {len(df_clean)} (At\u0131lan: {original_len - len(df_clean)})\")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_regressor(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    y_pred_tr = model.predict(X_tr)\n",
    "    y_pred_te = model.predict(X_te)\n",
    "\n",
    "    r2 = r2_score(y_te, y_pred_te)\n",
    "    rmse = np.sqrt(mean_squared_error(y_te, y_pred_te))\n",
    "    mae = mean_absolute_error(y_te, y_pred_te)\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"R\u00b2: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, S\u00fcre: {train_time:.2f}sn\")\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_te, y_pred_te, alpha=0.3)\n",
    "    plt.plot([y_te.min(), y_te.max()], [y_te.min(), y_te.max()], 'r--')\n",
    "    plt.xlabel('Ger\u00e7ek De\u011ferler')\n",
    "    plt.ylabel('Tahminler')\n",
    "    plt.title(f'{name}: Ger\u00e7ek vs Tahmin')\n",
    "    plt.savefig(f'reg_pred_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return {'Model': name, 'R2': r2, 'RMSE': rmse, 'MAE': mae, 'Training Time': train_time}\n",
    "\n",
    "lr = LinearRegression()\n",
    "results.append(evaluate_regressor(\"Linear Regression\", lr, X_train_scaled, y_train, X_test_scaled, y_test))\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "results.append(evaluate_regressor(\"Random Forest\", rf, X_train_scaled, y_train, X_test_scaled, y_test))\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "results.append(evaluate_regressor(\"Gradient Boosting\", gb, X_train_scaled, y_train, X_test_scaled, y_test))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nKar\u015f\u0131la\u015ft\u0131rma Sonu\u00e7lar\u0131:\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\nHangi \u00f6zellikler \u00f6nemli? (Feature Importance)\")\n",
    "try:\n",
    "\n",
    "    num_names = numeric_features.tolist()\n",
    "\n",
    "    try:\n",
    "        cat_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features).tolist()\n",
    "    except:\n",
    "        cat_names = [f\"Cat_{i}\" for i in range(X_train_scaled.shape[1] - len(num_names))]\n",
    "\n",
    "    all_features = num_names + cat_names\n",
    "\n",
    "    if len(all_features) != X_train_scaled.shape[1]:\n",
    "        print(\"Uyar\u0131: \u00d6zellik isimleri ile veri boyutu uyu\u015fmuyor, grafik \u00e7izilmeyecek.\")\n",
    "    else:\n",
    "        feature_importances = rf.feature_importances_\n",
    "        indices = np.argsort(feature_importances)[::-1][:10]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"En \u00d6nemli 10 \u00d6zellik (Random Forest)\")\n",
    "        plt.bar(range(10), feature_importances[indices], align=\"center\")\n",
    "        plt.xticks(range(10), [all_features[i] for i in indices], rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('regression_feature_importance.png')\n",
    "        print(\"\u00d6zellik \u00f6nem grafi\u011fi kaydedildi.\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature importance grafi\u011fi \u00e7izilirken hata: {e}\")\n",
    "\n",
    "print(\"\\nRegresyon i\u015flemi bitti.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Task\n",
    "Kodlar a\u015fa\u011f\u0131dad\u0131r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import time\n",
    "\n",
    "print(\"Veri Seti Y\u00fckleniyor (Most Streamed Spotify Songs 2024)...\")\n",
    "try:\n",
    "\n",
    "    df = pd.read_csv('Most Streamed Spotify Songs 2024.csv', encoding='latin1')\n",
    "    print(f\"Veri Boyutu: {df.shape}\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: 'Most Streamed Spotify Songs 2024.csv' dosyas\u0131 bulunamad\u0131!\")\n",
    "    exit()\n",
    "\n",
    "drop_cols = ['Track', 'Album Name', 'Artist', 'ISRC', 'All Time Rank', 'Release Date']\n",
    "\n",
    "cols_to_drop = [c for c in drop_cols if c in df.columns]\n",
    "X = df.drop(columns=cols_to_drop)\n",
    "\n",
    "for col in X.columns:\n",
    "\n",
    "    X[col] = pd.to_numeric(X[col].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "X = X.dropna(axis=1, how='all')\n",
    "\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"\u00d6zellik say\u0131s\u0131: {X.shape[1]}\")\n",
    "print(f\"\u00d6zellikler: {X.columns.tolist()}\")\n",
    "\n",
    "if not np.isfinite(X).all().all():\n",
    "    print(\"Sonsuz de\u011ferler temizleniyor...\")\n",
    "    X = X.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(f\"\u00d6zellik say\u0131s\u0131: {X.shape[1]}\")\n",
    "print(f\"\u00d6zellikler: {X.columns.tolist()}\")\n",
    "\n",
    "if len(X) > 10000:\n",
    "    print(\"Veri \u00e7ok b\u00fcy\u00fck oldu\u011fu i\u00e7in ilk 5000 sat\u0131r\u0131 al\u0131yorum.\n",
    "    X = X.iloc[:5000]\n",
    "\n",
    "print(\"\\n\u00d6l\u00e7ekleme...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_clustering(name, model_labels, X_data, time_taken):\n",
    "\n",
    "    if len(np.unique(model_labels)) < 2:\n",
    "        print(f\"{name}: Yetersiz k\u00fcme say\u0131s\u0131 (t\u00fcm\u00fc g\u00fcr\u00fclt\u00fc veya tek k\u00fcme).\")\n",
    "        return None\n",
    "\n",
    "    sil = silhouette_score(X_data, model_labels, sample_size=1000, random_state=42)\n",
    "    db = davies_bouldin_score(X_data, model_labels)\n",
    "\n",
    "    n_clusters = len(set(model_labels)) - (1 if -1 in model_labels else 0)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"K\u00fcme Say\u0131s\u0131: {n_clusters}\")\n",
    "    print(f\"Silhouette: {sil:.4f}, Davies-Bouldin: {db:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:,1], hue=model_labels, palette='viridis', legend='full', alpha=0.6)\n",
    "    plt.title(f'{name} Sonu\u00e7lar\u0131 (PCA \u0130ndirgeme)')\n",
    "    plt.savefig(f'clustering_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return {'Model': name, 'Clusters': n_clusters, 'Silhouette': sil, 'DB Index': db, 'Time': time_taken}\n",
    "\n",
    "print(\"En iyi k\u00fcme say\u0131s\u0131n\u0131 (K) bulmaya \u00e7al\u0131\u015ft\u0131r\u0131l\u0131yor.....\")\n",
    "best_k = 3\n",
    "best_score = -1\n",
    "scores = []\n",
    "\n",
    "for k in range(2, 7):\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    labels_temp = kmeans_temp.fit_predict(X_scaled)\n",
    "\n",
    "    score = silhouette_score(X_scaled, labels_temp, sample_size=1000, random_state=42)\n",
    "    scores.append((k, score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "\n",
    "print(f\"En iyi K de\u011feri: {best_k} (Skor: {best_score:.4f})\")\n",
    "\n",
    "start = time.time()\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "results.append(evaluate_clustering(f\"K-Means (K={best_k})\", kmeans_labels, X_scaled, time.time()-start))\n",
    "\n",
    "print(\"MiniBatch K-Means \u00e7al\u0131\u015ft\u0131r\u0131l\u0131yor...\")\n",
    "start = time.time()\n",
    "mb_kmeans = MiniBatchKMeans(n_clusters=4, random_state=42, batch_size=256)\n",
    "mb_labels = mb_kmeans.fit_predict(X_scaled)\n",
    "results.append(evaluate_clustering(\"MiniBatch KMeans\", mb_labels, X_scaled, time.time()-start))\n",
    "\n",
    "print(\"DBSCAN \u00e7al\u0131\u015ft\u0131r\u0131l\u0131yor... (Parametre ayar\u0131 kritik)\")\n",
    "start = time.time()\n",
    "\n",
    "dbscan = DBSCAN(eps=2.0, min_samples=10)\n",
    "db_labels = dbscan.fit_predict(X_scaled)\n",
    "res = evaluate_clustering(\"DBSCAN\", db_labels, X_scaled, time.time()-start)\n",
    "if res: results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSonu\u00e7lar\u0131n kar\u015f\u0131la\u015ft\u0131r\u0131lmas\u0131:\")\n",
    "print(results_df)\n",
    "\n",
    "try:\n",
    "    cols = X.columns.tolist()\n",
    "\n",
    "    x_col = 'Spotify Streams' if 'Spotify Streams' in cols else cols[0]\n",
    "    y_col = 'TikTok Views' if 'TikTok Views' in cols else (cols[1] if len(cols) > 1 else cols[0])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    sns.scatterplot(x=X[x_col], y=X[y_col], hue=kmeans_labels, palette='viridis', alpha=0.6)\n",
    "    plt.title(f'{x_col} vs {y_col} (K-Means K\u00fcmeleri)')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig('clustering_scatter_streams.png')\n",
    "    print(f\"Grafik kaydedildi.\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Ek grafik \u00e7izilirken hata: {e}\")\n",
    "\n",
    "print(\"\\nK\u00fcmeleme i\u015flemi bitti.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}